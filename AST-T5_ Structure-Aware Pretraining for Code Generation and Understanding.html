<!DOCTYPE html>
<!-- saved from url=(0035)https://arxiv.org/html/2401.03003v4 -->
<html lang="en" data-theme="light"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>AST-T5: Structure-Aware Pretraining for Code Generation and Understanding</title>
<!--Generated on Sun Jun 23 01:24:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/bootstrap.bundle.min.js.download"></script>
<script src="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/html2canvas.min.js.download"></script>
<script src="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/addons_new.js.download"></script>
<script src="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/feedbackOverlay.js.download"></script>
<meta content="PLACEHOLDER: Keywords" lang="en" name="keywords">
<!--<base href="/html/2401.03003v4/">--><base href="."><link rel="stylesheet" href="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/utz6mli.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2401.03003v4">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2401.03003v4/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2401.03003v4">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2401.03003v4" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S1" title="In AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S2" title="In AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S2.SS0.SSS0.Px1" title="In 2 Related Work ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">Language Models for Code.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S2.SS0.SSS0.Px2" title="In 2 Related Work ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">Efforts Toward Unified Models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S2.SS0.SSS0.Px3" title="In 2 Related Work ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">Leveraging Code Structure in Pretraining.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3" title="In AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.SS1" title="In 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Parsing Code Into ASTs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.SS2" title="In 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>AST-Aware Segmentation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.SS3" title="In 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Pretraining with Span Corruption</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.SS4" title="In 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>AST-Aware Subtree Corruption</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.SS4.SSS0.Px1" title="In 3.4 AST-Aware Subtree Corruption ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">Subtree Masking.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.SS4.SSS0.Px2" title="In 3.4 AST-Aware Subtree Corruption ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">Pretraining Objective.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S4" title="In AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S4.SS0.SSS0.Px1" title="In 4 Experimental Setup ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">Model Architecture.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S4.SS0.SSS0.Px2" title="In 4 Experimental Setup ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">Pretraining.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S4.SS0.SSS0.Px3" title="In 4 Experimental Setup ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">Evaluation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S4.SS0.SSS0.Px4" title="In 4 Experimental Setup ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">Baselines.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5" title="In AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Evaluation Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.SS1" title="In 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Pretraining Procedure Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.SS1.SSS0.Px1" title="In 5.1 Pretraining Procedure Analysis ‣ 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">AST-Aware Segmentation enhances code language models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.SS1.SSS0.Px2" title="In 5.1 Pretraining Procedure Analysis ‣ 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">AST-Aware Span Corruption further boosts generation performance.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.SS1.SSS0.Px3" title="In 5.1 Pretraining Procedure Analysis ‣ 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title">Increasing masking ratio improves generation performance.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.SS2" title="In 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Main Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.SS2.SSS0.Px1" title="In 5.2 Main Results ‣ 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_ERROR undefined">\nolbreaks</span>AST-T5 excels as a unified and parameter-efficient LM for various code-related tasks.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.SS2.SSS0.Px2" title="In 5.2 Main Results ‣ 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_ERROR undefined">\nolbreaks</span>AST-T5 exhibits unique strengths in transpilation through AST-awareness.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S6" title="In AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion and Future Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1" title="In AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.SS1" title="In Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.SS2" title="In Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>More about AST-Aware Segmentation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.SS3" title="In Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Pretraining Hyperparameters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.SS4" title="In Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Evaluation Results on EvalPlus</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.SS5" title="In Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.5 </span>Evaluation Results on Multi-Lingual Code Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.SS6" title="In Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.6 </span>Evaluation Results in CodeBLEU</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found">
      <button aria-label="Dismiss alert" onclick="closePopup()">
          <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44" aria-hidden="true" focusable="false">
          <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
          <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
          </svg></span>
      </button>
      <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
          <ul arial-label="Unsupported packages used in this paper">
              <li>failed: minted</li><li>failed: inconsolata</li><li>failed: nolbreaks</li>
          </ul>
      <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
    </div><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: arXiv.org perpetual non-exclusive license</a><div id="watermark-tr">arXiv:2401.03003v4 [cs.SE] 23 Jun 2024</div></div>
<article class="ltx_document ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">AST-T5: Structure-Aware Pretraining for Code Generation and Understanding</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Linyuan Gong
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mostafa Elhoushi
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Alvin Cheung
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id1.id1">Large language models (LLMs) have made significant advancements in code-related tasks, yet many LLMs treat code as simple sequences, neglecting its structured nature. We introduce <span class="ltx_ERROR undefined" id="id1.id1.1">\nolbreaks</span>AST-T5, a novel pretraining paradigm that leverages the Abstract Syntax Tree (AST) for enhanced code generation, transpilation, and understanding. Using dynamic programming, our AST-Aware Segmentation retains code structure, while our AST-Aware Span Corruption objective equips the model to reconstruct various code structures. Unlike other models, <span class="ltx_ERROR undefined" id="id1.id1.2">\nolbreaks</span>AST-T5 avoids complex program analyses or architectural changes, so it integrates seamlessly with any encoder-decoder Transformer. Evaluations show that <span class="ltx_ERROR undefined" id="id1.id1.3">\nolbreaks</span>AST-T5 consistently outperforms similar-sized LMs across various code-related tasks including HumanEval and MBPP. Structure-awareness makes <span class="ltx_ERROR undefined" id="id1.id1.4">\nolbreaks</span>AST-T5 particularly powerful in code-to-code tasks, surpassing CodeT5 by 2 points in exact match score for the Bugs2Fix task and by 3 points in exact match score for Java-C# Transpilation in CodeXGLUE. Our code and model are publicly available at
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://annonymized/" title="">https://annonymized</a>
.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_keywords">PLACEHOLDER: Keywords
</div>
<div class="ltx_para" id="p2">
<br class="ltx_break">
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S1.F1">
<br class="ltx_break">
<p class="ltx_p ltx_align_center ltx_align_center" id="S1.F1.1.1"><span class="ltx_text" id="S1.F1.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="268" id="S1.F1.1.1.1.g1" src="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/x1.png" width="510"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.6.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.7.2" style="font-size:90%;">Comparison of AST-Aware Subtree Corruption and Vanilla T5 using a Python factorial function. Both methods replace masked spans with sentinel tokens (special tokens added to the vocabulary, shown as <span class="ltx_text ltx_font_typewriter" id="S1.F1.7.2.1" style="color:#A61140;">[X]</span>, <span class="ltx_text ltx_font_typewriter" id="S1.F1.7.2.2" style="color:#A67B11;">[Y]</span>, and <span class="ltx_text ltx_font_typewriter" id="S1.F1.7.2.3" style="color:#11A61D;">[Z]</span> in the figure), with output sequences containing the original masked tokens. Inputs and targets are shown in byte-pair encoding (BPE); for instance, “factorial” is encoded into “fact” and “orial”. Unlike Vanilla T5, which masks random spans without considering code structure, our approach specifically targets spans aligned with AST subtrees, like expressions and statements.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">We have witnessed the transformative impact of large language models (LLMs) on various aspects of artificial intelligence in recent years&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Brown et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib9" title="">2020</a>; Ouyang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib30" title="">2022</a>; Touvron et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib40" title="">2023</a>)</cite>, especially in code generation and understanding&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Feng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib15" title="">2020</a>; Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib43" title="">2021</a>; Rozière et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib35" title="">2023</a>)</cite>. By pretraining on massive code corpora such as the GitHub corpus, LLMs learns rich representations, thereby becoming powerful tools for various downstream applications such as text-to-code generation&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib10" title="">2021a</a>; Austin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib5" title="">2021</a>; Iyer et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib19" title="">2018</a>)</cite>, code-to-code transpilation&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib27" title="">2021</a>; Lachaux et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib22" title="">2020</a>; Tufano et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib41" title="">2019</a>)</cite>, and code understanding (mapping code to classification labels)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib46" title="">2019</a>; Svajlenko et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib38" title="">2014</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Despite these impressive advances, most existing models interpret code as mere sequences of subword tokens, overlooking its intrinsic structured nature. Prior research has shown that leveraging the Abstract Syntax Tree (AST) of code can significantly improve performance on code-related tasks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Guo et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib17" title="">2021</a>; Tipirneni et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib39" title="">2023</a>)</cite>. Some studies also use code obfuscation during pretraining to teach models about abstract code structures&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Roziere et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib34" title="">2021</a>; Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib43" title="">2021</a>)</cite>. However, these models often rely on computationally expensive processes like Control-Flow Analysis (CFA), obfuscation, or even actual code execution. Such dependency limits their scalability and imposes stringent conditions like code executability. Consequently, these methods may struggle with real-world code, especially in intricate languages like C/C++, where comprehensive analysis remains elusive.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this study, we propose <span class="ltx_ERROR undefined" id="S1.p3.1.1">\nolbreaks</span>AST-T5, a pretraining paradigm that leverages the Abstract Syntax Tree (AST) structure of code. The key contribution in <span class="ltx_ERROR undefined" id="S1.p3.1.2">\nolbreaks</span>AST-T5 is a simple yet effective way to exploit code semantics, without the need to run expensive program analysis or execution. Using a lightweight, multi-language parser called Tree-sitter<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://tree-sitter.github.io/tree-sitter/" title="">https://tree-sitter.github.io/tree-sitter/</a></span></span></span>, our approach has broad applicability across all syntactically well-defined programming languages. After we parse code into ASTs, we use a dynamic programming-based segmentation algorithm for AST-aware code segmentation to maintain the structural integrity of the input code. Using our novel AST-Aware Span Corruption technique, the model is pretrained to reconstruct various code structures, ranging from individual tokens to entire function bodies. Together, our approach offers three key advantages: (1) enriched bidirectional encoding for improved code understanding, (2) the ability to coherently generate code structures, and (3) a unified, structure-aware pretraining framework that boosts performance across a variety of code-related tasks, particularly in code transpilation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In addition, other than our specialized AST-aware masking approach, <span class="ltx_ERROR undefined" id="S1.p4.1.1">\nolbreaks</span>AST-T5 introduces no architecture changes or additional heads, and our pretraining objective remains the same as Vanilla T5. This compatibility enables seamless integration of our model as a drop-in replacement for any T5 variant.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In our experiments, <span class="ltx_ERROR undefined" id="S1.p5.1.1">\nolbreaks</span>AST-T5 consistently outperforms baselines in code generation, transpilation, and understanding tasks. Through controlled experiments, we empirically demonstrate that these advancements are attributed to our AST-aware pretraining techniques. Notably, <span class="ltx_ERROR undefined" id="S1.p5.1.2">\nolbreaks</span>AST-T5 not only outperforms similar-sized models like CodeT5 and CodeT5+ across various benchmarks but also remains competitive with, or occasionally even exceeds, the performance of much larger models using the HumanEval&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib10" title="">2021a</a>)</cite> and the MBPP&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Austin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib5" title="">2021</a>)</cite> benchmarks. Furthermore, the inherent AST-awareness of <span class="ltx_ERROR undefined" id="S1.p5.1.3">\nolbreaks</span>AST-T5 offers unique advantages in structure-sensitive tasks, such as code-to-code transpilation and Clone Detection, highlighting its effectiveness at capturing the structural nuances of code.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Language Models for Code.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Language models (LMs) extended their use from NLP to code understanding and generation. Encoder-only models generally excel in code understanding when finetuned with classifiers&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Feng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib15" title="">2020</a>)</cite>, while decoder-only models are optimized for code generation through their autoregressive nature&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib10" title="">2021a</a>; Fried et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib16" title="">2023</a>; Nijkamp et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib29" title="">2023b</a>)</cite>. However, these models can falter outside their primary domains of expertise or require increased resources for comparable outcomes. Our work focuses on encoder-decoder models, aiming to efficiently balance performance in both understanding and generation tasks without excessive computational demands.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Efforts Toward Unified Models.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">Extending NLP models like BART&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib23" title="">2019</a>)</cite> and T5&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Raffel et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib32" title="">2020</a>)</cite>, several studies have developed encoder-decoder architectures, such as PLBART&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ahmad et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib1" title="">2021</a>)</cite> and CodeT5&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib43" title="">2021</a>)</cite>, to perform well in diverse code-related tasks. Although these models show broader utility, they struggle with generating coherent, executable code in complex scenarios like HumanEval&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib10" title="">2021a</a>)</cite>. CodeT5+&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib44" title="">2023</a>)</cite> seeks to address this limitation through an intricate multi-task pretraining strategy across five objectives.
In contrast, our proposed model, AST-T5, uses a novel AST-Aware pretraining paradigm to become a unified model capable of generating fluent code and maintaining superior performance in code understanding tasks. Moreover, <span class="ltx_ERROR undefined" id="S2.SS0.SSS0.Px2.p1.1.1">\nolbreaks</span>AST-T5 is more streamlined, because it only uses a single pretraining objective.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Leveraging Code Structure in Pretraining.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">Code differs from natural language in two key aspects: its executability and strict structural syntax. Previous research leveraged execution traces for improving model performance&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib11" title="">2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib12" title="">2021b</a>; Shojaee et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib37" title="">2023</a>)</cite>, but this approach faces scalability challenges when applied to large, web-crawled code datasets used in pretraining. Regarding code’s structured nature, various studies have integrated syntactic elements into neural network models. <cite class="ltx_cite ltx_citemacro_citet">Li et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib24" title="">2018</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Kim et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib20" title="">2021</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Zügner et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib47" title="">2021</a>)</cite> add AST-Aware attention mechanisms in their models, while <cite class="ltx_cite ltx_citemacro_citet">Alon et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib3" title="">2020</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Rabinovich et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib31" title="">2017</a>)</cite> focus on modeling AST node expansion operations rather than traditional code tokens. In parallel, <cite class="ltx_cite ltx_citemacro_citet">Guo et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib17" title="">2021</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Allamanis et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib2" title="">2017</a>)</cite> explore DFG-Aware attention mechanisms and Graph Neural Networks (GNNs), to interpret code based on its Data Flow Graph (DFG). StructCoder&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Tipirneni et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib39" title="">2023</a>)</cite> enriches the code input by appending AST and DFG as additional features. These methods, however, necessitate parsing or static analysis for downstream tasks, which is less feasible for incomplete or incorrect code scenarios like bug fixing.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p2.1">Our work, <span class="ltx_ERROR undefined" id="S2.SS0.SSS0.Px3.p2.1.1">\nolbreaks</span>AST-T5, aligns with methods that utilize code structure only in pretraining, like DOBF&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Roziere et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib34" title="">2021</a>)</cite> and CodeT5&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib43" title="">2021</a>)</cite>, which obfuscate inputs to force the model to grasp abstract structures. Our approach uniquely diverges by using AST-driven segmentation and masking in T5 span corruption during pretraining. This novel approach offers a more refined pretraining signal compared to structure-agnostic T5, equipping our model to proficiently encode and generate semantically coherent code structures.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we present <span class="ltx_ERROR undefined" id="S3.p1.1.1">\nolbreaks</span>AST-T5, a novel pretraining framework for code-based language models that harnesses the power of Abstract Syntax Trees (ASTs). First, <span class="ltx_ERROR undefined" id="S3.p1.1.2">\nolbreaks</span>AST-T5 parses code into ASTs to enable a deeper understanding of code structure. Leveraging this structure, we introduce AST-Aware Segmentation, an algorithm designed to address Transformer token limits while retaining the semantic coherence of the code. Second, we introduce AST-Aware Span Corruption, a masking technique that pretrains <span class="ltx_ERROR undefined" id="S3.p1.1.3">\nolbreaks</span>AST-T5 to reconstruct code structures ranging from individual tokens to entire function bodies, enhancing both its flexibility and structure-awareness.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Parsing Code Into ASTs</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Unlike traditional language models on code that handle code as simple sequences of subword tokens, <span class="ltx_ERROR undefined" id="S3.SS1.p1.1.1">\nolbreaks</span>AST-T5 leverages the Abstract Syntax Tree (AST) of code to gain semantic insights. For parsing purposes, we assume the provided code is syntactically valid—a reasonable assumption for tasks like code transpilation and understanding. Instead of the often computationally-intensive or infeasible methods of Control-Flow Analysis (CFA) or code execution&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Guo et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib17" title="">2021</a>; Tipirneni et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib39" title="">2023</a>)</cite>, our method only requires the code to be parsable. We use Tree-sitter, a multi-language parser, to construct the ASTs, where each subtree represents a consecutive span of subword tokens, and every leaf node represents an individual token.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>AST-Aware Segmentation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In this subsection, we describe our AST-Aware Segmentation method, which splits lengthy code files into chunks in a structure-perserving manner.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F2">
<br class="ltx_break">
<p class="ltx_p ltx_align_center ltx_align_center" id="S3.F2.1.1"><span class="ltx_text" id="S3.F2.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="223" id="S3.F2.1.1.1.g1" src="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/x2.png" width="530"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.4.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S3.F2.5.2" style="font-size:90%;">Comparison between Greedy Segmentation and AST-Aware Segmentation: For a 112-token code example with <span class="ltx_text ltx_font_typewriter" id="S3.F2.5.2.1">max_len</span> set at 48, Greedy Segmentation places the first 48 tokens in Block 1, the next 48 tokens in Block 2, and the remaining in Block 3, disrupting the structural integrity of the code. In contrast, AST-Aware Segmentation uses a dynamic programming algorithm to smartly partition the code, aligning with boundaries of member functions or major function branches, thereby preserving the code’s structure. The accompanying AST, with some levels pruned for clarity, corroborates that these segmentations indeed coincide with key subtree demarcations.
</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Segmentation in language model pretraining</span> is a critical yet often overlooked aspect. Transformer LMs impose token limits on input sequences, making segmentation essential for fitting these inputs within the <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p2.1.2">max_len</span> constraint. A naive approach is Greedy Segmentation, where each chunk, except the last, contains exactly <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p2.1.3">max_len</span> tokens <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.F2" title="In 3.2 AST-Aware Segmentation ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a> (Left). This strategy has been widely adopted in previous works, such as CodeT5&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib43" title="">2021</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Research in NLP by <cite class="ltx_cite ltx_citemacro_citet">Liu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib26" title="">2019</a>)</cite> underscores that segmentation respecting sentence and document boundaries outperforms the greedy strategy. Given programming language’s inherently structured nature, which is arguably more complex than natural language, a more sophisticated segmentation approach is even more important. However, this area remains largely unexplored.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">AST-Aware Segmentation</span> is our novel approach designed to preserve the AST structure of code during segmentation. Unlike Greedy Segmentation, which can indiscriminately fragment AST structures, our method strategically minimizes such disruptions. As illustrated in the example in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.F2" title="In 3.2 AST-Aware Segmentation ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, Greedy Segmentation leads to nine instances of AST breaks—between Block 1 and Block 2, it breaks <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.2">If</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.3">FuncDef</span>, and <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.4">ClassDef</span>; between Block 2 and Block 3, it breaks <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.5">Attr</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.6">BinaryExpr</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.7">While</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.8">If</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.9">FuncDef</span>, and <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.10">ClassDef</span>. In contrast, our AST-Aware approach results in only three breaks: between Block 1 and Block 2, it breaks <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.11">ClassDef</span>, and between Block 2 and Block 3, it breaks <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.12">FuncDef</span> and <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p4.1.13">ClassDef</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">To identify optimal partition boundaries, we developed the following dynamic programming (DP)-based algorithm:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.2">We construct an array <span class="ltx_text ltx_font_typewriter" id="S3.I1.i1.p1.2.1">cost</span>, where <span class="ltx_text ltx_font_typewriter" id="S3.I1.i1.p1.2.2">cost[i]</span> denotes the number of AST-structure breaks that would occur if partitioning happened right after token <math alttext="i" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.1"><semantics id="S3.I1.i1.p1.1.m1.1a"><mi id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><ci id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.1.m1.1d">italic_i</annotation></semantics></math>. This array is populated by traversing the AST and incrementing <span class="ltx_text ltx_font_typewriter" id="S3.I1.i1.p1.2.3">cost[l..r - 1]</span> by 1 for each span <math alttext="[l,r]" class="ltx_Math" display="inline" id="S3.I1.i1.p1.2.m2.2"><semantics id="S3.I1.i1.p1.2.m2.2a"><mrow id="S3.I1.i1.p1.2.m2.2.3.2" xref="S3.I1.i1.p1.2.m2.2.3.1.cmml"><mo id="S3.I1.i1.p1.2.m2.2.3.2.1" stretchy="false" xref="S3.I1.i1.p1.2.m2.2.3.1.cmml">[</mo><mi id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml">l</mi><mo id="S3.I1.i1.p1.2.m2.2.3.2.2" xref="S3.I1.i1.p1.2.m2.2.3.1.cmml">,</mo><mi id="S3.I1.i1.p1.2.m2.2.2" xref="S3.I1.i1.p1.2.m2.2.2.cmml">r</mi><mo id="S3.I1.i1.p1.2.m2.2.3.2.3" stretchy="false" xref="S3.I1.i1.p1.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.2b"><interval closure="closed" id="S3.I1.i1.p1.2.m2.2.3.1.cmml" xref="S3.I1.i1.p1.2.m2.2.3.2"><ci id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1">𝑙</ci><ci id="S3.I1.i1.p1.2.m2.2.2.cmml" xref="S3.I1.i1.p1.2.m2.2.2">𝑟</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.2c">[l,r]</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.2.m2.2d">[ italic_l , italic_r ]</annotation></semantics></math> associated with an AST subtree.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.3">We define a 2-D array <span class="ltx_text ltx_font_typewriter" id="S3.I1.i2.p1.3.1">dp</span>, where <span class="ltx_text ltx_font_typewriter" id="S3.I1.i2.p1.3.2">dp[k, i]</span> represents the the minimum total number of AST-structure breaks when <math alttext="k" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.1"><semantics id="S3.I1.i2.p1.1.m1.1a"><mi id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><ci id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.1d">italic_k</annotation></semantics></math> partitions are made for the first <math alttext="i" class="ltx_Math" display="inline" id="S3.I1.i2.p1.2.m2.1"><semantics id="S3.I1.i2.p1.2.m2.1a"><mi id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.2.m2.1d">italic_i</annotation></semantics></math> tokens, ending the last partition right after the <math alttext="i" class="ltx_Math" display="inline" id="S3.I1.i2.p1.3.m3.1"><semantics id="S3.I1.i2.p1.3.m3.1a"><mi id="S3.I1.i2.p1.3.m3.1.1" xref="S3.I1.i2.p1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.3.m3.1b"><ci id="S3.I1.i2.p1.3.m3.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.3.m3.1d">italic_i</annotation></semantics></math>-th token. The state transition equation is:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\texttt{dp}[k,i]=\texttt{cost}[i]+\min_{i-\texttt{max\_len}\leq j%
&lt;i}\texttt{dp}[k-1,j]" class="ltx_Math" display="inline" id="S3.E1.m1.5"><semantics id="S3.E1.m1.5a"><mrow id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml"><mrow id="S3.E1.m1.5.5.3" xref="S3.E1.m1.5.5.3.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.5.5.3.2" xref="S3.E1.m1.5.5.3.2a.cmml">dp</mtext><mo id="S3.E1.m1.5.5.3.1" xref="S3.E1.m1.5.5.3.1.cmml">⁢</mo><mrow id="S3.E1.m1.5.5.3.3.2" xref="S3.E1.m1.5.5.3.3.1.cmml"><mo id="S3.E1.m1.5.5.3.3.2.1" stretchy="false" xref="S3.E1.m1.5.5.3.3.1.cmml">[</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">k</mi><mo id="S3.E1.m1.5.5.3.3.2.2" xref="S3.E1.m1.5.5.3.3.1.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">i</mi><mo id="S3.E1.m1.5.5.3.3.2.3" stretchy="false" xref="S3.E1.m1.5.5.3.3.1.cmml">]</mo></mrow></mrow><mo id="S3.E1.m1.5.5.2" xref="S3.E1.m1.5.5.2.cmml">=</mo><mrow id="S3.E1.m1.5.5.1" xref="S3.E1.m1.5.5.1.cmml"><mrow id="S3.E1.m1.5.5.1.3" xref="S3.E1.m1.5.5.1.3.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.5.5.1.3.2" xref="S3.E1.m1.5.5.1.3.2a.cmml">cost</mtext><mo id="S3.E1.m1.5.5.1.3.1" xref="S3.E1.m1.5.5.1.3.1.cmml">⁢</mo><mrow id="S3.E1.m1.5.5.1.3.3.2" xref="S3.E1.m1.5.5.1.3.3.1.cmml"><mo id="S3.E1.m1.5.5.1.3.3.2.1" stretchy="false" xref="S3.E1.m1.5.5.1.3.3.1.1.cmml">[</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">i</mi><mo id="S3.E1.m1.5.5.1.3.3.2.2" stretchy="false" xref="S3.E1.m1.5.5.1.3.3.1.1.cmml">]</mo></mrow></mrow><mo id="S3.E1.m1.5.5.1.2" xref="S3.E1.m1.5.5.1.2.cmml">+</mo><mrow id="S3.E1.m1.5.5.1.1" xref="S3.E1.m1.5.5.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1.3" xref="S3.E1.m1.5.5.1.1.3.cmml"><munder id="S3.E1.m1.5.5.1.1.3.1" xref="S3.E1.m1.5.5.1.1.3.1.cmml"><mi id="S3.E1.m1.5.5.1.1.3.1.2" xref="S3.E1.m1.5.5.1.1.3.1.2.cmml">min</mi><mrow id="S3.E1.m1.5.5.1.1.3.1.3" xref="S3.E1.m1.5.5.1.1.3.1.3.cmml"><mrow id="S3.E1.m1.5.5.1.1.3.1.3.2" xref="S3.E1.m1.5.5.1.1.3.1.3.2.cmml"><mi id="S3.E1.m1.5.5.1.1.3.1.3.2.2" xref="S3.E1.m1.5.5.1.1.3.1.3.2.2.cmml">i</mi><mo id="S3.E1.m1.5.5.1.1.3.1.3.2.1" xref="S3.E1.m1.5.5.1.1.3.1.3.2.1.cmml">−</mo><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.5.5.1.1.3.1.3.2.3" xref="S3.E1.m1.5.5.1.1.3.1.3.2.3a.cmml">max_len</mtext></mrow><mo id="S3.E1.m1.5.5.1.1.3.1.3.3" xref="S3.E1.m1.5.5.1.1.3.1.3.3.cmml">≤</mo><mi id="S3.E1.m1.5.5.1.1.3.1.3.4" xref="S3.E1.m1.5.5.1.1.3.1.3.4.cmml">j</mi><mo id="S3.E1.m1.5.5.1.1.3.1.3.5" xref="S3.E1.m1.5.5.1.1.3.1.3.5.cmml">&lt;</mo><mi id="S3.E1.m1.5.5.1.1.3.1.3.6" xref="S3.E1.m1.5.5.1.1.3.1.3.6.cmml">i</mi></mrow></munder><mo id="S3.E1.m1.5.5.1.1.3a" lspace="0.167em" xref="S3.E1.m1.5.5.1.1.3.cmml">⁡</mo><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.5.5.1.1.3.2" xref="S3.E1.m1.5.5.1.1.3.2a.cmml">dp</mtext></mrow><mo id="S3.E1.m1.5.5.1.1.2" xref="S3.E1.m1.5.5.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.5.5.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.2.cmml"><mo id="S3.E1.m1.5.5.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.5.5.1.1.1.2.cmml">[</mo><mrow id="S3.E1.m1.5.5.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.cmml"><mi id="S3.E1.m1.5.5.1.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.1.1.2.cmml">k</mi><mo id="S3.E1.m1.5.5.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.1.cmml">−</mo><mn id="S3.E1.m1.5.5.1.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.E1.m1.5.5.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.2.cmml">,</mo><mi id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml">j</mi><mo id="S3.E1.m1.5.5.1.1.1.1.4" stretchy="false" xref="S3.E1.m1.5.5.1.1.1.2.cmml">]</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.5b"><apply id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5"><eq id="S3.E1.m1.5.5.2.cmml" xref="S3.E1.m1.5.5.2"></eq><apply id="S3.E1.m1.5.5.3.cmml" xref="S3.E1.m1.5.5.3"><times id="S3.E1.m1.5.5.3.1.cmml" xref="S3.E1.m1.5.5.3.1"></times><ci id="S3.E1.m1.5.5.3.2a.cmml" xref="S3.E1.m1.5.5.3.2"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.5.5.3.2.cmml" xref="S3.E1.m1.5.5.3.2">dp</mtext></ci><interval closure="closed" id="S3.E1.m1.5.5.3.3.1.cmml" xref="S3.E1.m1.5.5.3.3.2"><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝑘</ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">𝑖</ci></interval></apply><apply id="S3.E1.m1.5.5.1.cmml" xref="S3.E1.m1.5.5.1"><plus id="S3.E1.m1.5.5.1.2.cmml" xref="S3.E1.m1.5.5.1.2"></plus><apply id="S3.E1.m1.5.5.1.3.cmml" xref="S3.E1.m1.5.5.1.3"><times id="S3.E1.m1.5.5.1.3.1.cmml" xref="S3.E1.m1.5.5.1.3.1"></times><ci id="S3.E1.m1.5.5.1.3.2a.cmml" xref="S3.E1.m1.5.5.1.3.2"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.5.5.1.3.2.cmml" xref="S3.E1.m1.5.5.1.3.2">cost</mtext></ci><apply id="S3.E1.m1.5.5.1.3.3.1.cmml" xref="S3.E1.m1.5.5.1.3.3.2"><csymbol cd="latexml" id="S3.E1.m1.5.5.1.3.3.1.1.cmml" xref="S3.E1.m1.5.5.1.3.3.2.1">delimited-[]</csymbol><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">𝑖</ci></apply></apply><apply id="S3.E1.m1.5.5.1.1.cmml" xref="S3.E1.m1.5.5.1.1"><times id="S3.E1.m1.5.5.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2"></times><apply id="S3.E1.m1.5.5.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.3"><apply id="S3.E1.m1.5.5.1.1.3.1.cmml" xref="S3.E1.m1.5.5.1.1.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.3.1.1.cmml" xref="S3.E1.m1.5.5.1.1.3.1">subscript</csymbol><min id="S3.E1.m1.5.5.1.1.3.1.2.cmml" xref="S3.E1.m1.5.5.1.1.3.1.2"></min><apply id="S3.E1.m1.5.5.1.1.3.1.3.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3"><and id="S3.E1.m1.5.5.1.1.3.1.3a.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3"></and><apply id="S3.E1.m1.5.5.1.1.3.1.3b.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3"><leq id="S3.E1.m1.5.5.1.1.3.1.3.3.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3.3"></leq><apply id="S3.E1.m1.5.5.1.1.3.1.3.2.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3.2"><minus id="S3.E1.m1.5.5.1.1.3.1.3.2.1.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3.2.1"></minus><ci id="S3.E1.m1.5.5.1.1.3.1.3.2.2.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3.2.2">𝑖</ci><ci id="S3.E1.m1.5.5.1.1.3.1.3.2.3a.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3.2.3"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.5.5.1.1.3.1.3.2.3.cmml" mathsize="70%" xref="S3.E1.m1.5.5.1.1.3.1.3.2.3">max_len</mtext></ci></apply><ci id="S3.E1.m1.5.5.1.1.3.1.3.4.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3.4">𝑗</ci></apply><apply id="S3.E1.m1.5.5.1.1.3.1.3c.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3"><lt id="S3.E1.m1.5.5.1.1.3.1.3.5.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3.5"></lt><share href="https://arxiv.org/html/2401.03003v4#S3.E1.m1.5.5.1.1.3.1.3.4.cmml" id="S3.E1.m1.5.5.1.1.3.1.3d.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3"></share><ci id="S3.E1.m1.5.5.1.1.3.1.3.6.cmml" xref="S3.E1.m1.5.5.1.1.3.1.3.6">𝑖</ci></apply></apply></apply><ci id="S3.E1.m1.5.5.1.1.3.2a.cmml" xref="S3.E1.m1.5.5.1.1.3.2"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.5.5.1.1.3.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2">dp</mtext></ci></apply><interval closure="closed" id="S3.E1.m1.5.5.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1"><apply id="S3.E1.m1.5.5.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1"><minus id="S3.E1.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1"></minus><ci id="S3.E1.m1.5.5.1.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.2">𝑘</ci><cn id="S3.E1.m1.5.5.1.1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.5.5.1.1.1.1.1.3">1</cn></apply><ci id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4">𝑗</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.5c">\displaystyle\texttt{dp}[k,i]=\texttt{cost}[i]+\min_{i-\texttt{max\_len}\leq j%
&lt;i}\texttt{dp}[k-1,j]</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.5d">dp [ italic_k , italic_i ] = cost [ italic_i ] + roman_min start_POSTSUBSCRIPT italic_i - max_len ≤ italic_j &lt; italic_i end_POSTSUBSCRIPT dp [ italic_k - 1 , italic_j ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.3">While the naive DP algorithm has a quadratic time complexity <math alttext="O(n^{2})" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.1"><semantics id="S3.I1.i3.p1.1.m1.1a"><mrow id="S3.I1.i3.p1.1.m1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.cmml"><mi id="S3.I1.i3.p1.1.m1.1.1.3" xref="S3.I1.i3.p1.1.m1.1.1.3.cmml">O</mi><mo id="S3.I1.i3.p1.1.m1.1.1.2" xref="S3.I1.i3.p1.1.m1.1.1.2.cmml">⁢</mo><mrow id="S3.I1.i3.p1.1.m1.1.1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.1.1.1.cmml"><mo id="S3.I1.i3.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S3.I1.i3.p1.1.m1.1.1.1.1.1.cmml">(</mo><msup id="S3.I1.i3.p1.1.m1.1.1.1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.1.1.1.cmml"><mi id="S3.I1.i3.p1.1.m1.1.1.1.1.1.2" xref="S3.I1.i3.p1.1.m1.1.1.1.1.1.2.cmml">n</mi><mn id="S3.I1.i3.p1.1.m1.1.1.1.1.1.3" xref="S3.I1.i3.p1.1.m1.1.1.1.1.1.3.cmml">2</mn></msup><mo id="S3.I1.i3.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S3.I1.i3.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.1b"><apply id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1"><times id="S3.I1.i3.p1.1.m1.1.1.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.2"></times><ci id="S3.I1.i3.p1.1.m1.1.1.3.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3">𝑂</ci><apply id="S3.I1.i3.p1.1.m1.1.1.1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.I1.i3.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1">superscript</csymbol><ci id="S3.I1.i3.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1.1.2">𝑛</ci><cn id="S3.I1.i3.p1.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.I1.i3.p1.1.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.1c">O(n^{2})</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.m1.1d">italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math> relative to the code file length <math alttext="n" class="ltx_Math" display="inline" id="S3.I1.i3.p1.2.m2.1"><semantics id="S3.I1.i3.p1.2.m2.1a"><mi id="S3.I1.i3.p1.2.m2.1.1" xref="S3.I1.i3.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.2.m2.1b"><ci id="S3.I1.i3.p1.2.m2.1.1.cmml" xref="S3.I1.i3.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.2.m2.1d">italic_n</annotation></semantics></math>, it can be optimized to <math alttext="O(n^{2}/\texttt{max\_len})" class="ltx_Math" display="inline" id="S3.I1.i3.p1.3.m3.1"><semantics id="S3.I1.i3.p1.3.m3.1a"><mrow id="S3.I1.i3.p1.3.m3.1.1" xref="S3.I1.i3.p1.3.m3.1.1.cmml"><mi id="S3.I1.i3.p1.3.m3.1.1.3" xref="S3.I1.i3.p1.3.m3.1.1.3.cmml">O</mi><mo id="S3.I1.i3.p1.3.m3.1.1.2" xref="S3.I1.i3.p1.3.m3.1.1.2.cmml">⁢</mo><mrow id="S3.I1.i3.p1.3.m3.1.1.1.1" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.cmml"><mo id="S3.I1.i3.p1.3.m3.1.1.1.1.2" stretchy="false" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.I1.i3.p1.3.m3.1.1.1.1.1" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.cmml"><msup id="S3.I1.i3.p1.3.m3.1.1.1.1.1.2" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.2.cmml"><mi id="S3.I1.i3.p1.3.m3.1.1.1.1.1.2.2" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.2.2.cmml">n</mi><mn id="S3.I1.i3.p1.3.m3.1.1.1.1.1.2.3" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.2.3.cmml">2</mn></msup><mo id="S3.I1.i3.p1.3.m3.1.1.1.1.1.1" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.1.cmml">/</mo><mtext class="ltx_mathvariant_monospace" id="S3.I1.i3.p1.3.m3.1.1.1.1.1.3" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.3a.cmml">max_len</mtext></mrow><mo id="S3.I1.i3.p1.3.m3.1.1.1.1.3" stretchy="false" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.3.m3.1b"><apply id="S3.I1.i3.p1.3.m3.1.1.cmml" xref="S3.I1.i3.p1.3.m3.1.1"><times id="S3.I1.i3.p1.3.m3.1.1.2.cmml" xref="S3.I1.i3.p1.3.m3.1.1.2"></times><ci id="S3.I1.i3.p1.3.m3.1.1.3.cmml" xref="S3.I1.i3.p1.3.m3.1.1.3">𝑂</ci><apply id="S3.I1.i3.p1.3.m3.1.1.1.1.1.cmml" xref="S3.I1.i3.p1.3.m3.1.1.1.1"><divide id="S3.I1.i3.p1.3.m3.1.1.1.1.1.1.cmml" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.1"></divide><apply id="S3.I1.i3.p1.3.m3.1.1.1.1.1.2.cmml" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.I1.i3.p1.3.m3.1.1.1.1.1.2.1.cmml" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.2">superscript</csymbol><ci id="S3.I1.i3.p1.3.m3.1.1.1.1.1.2.2.cmml" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.2.2">𝑛</ci><cn id="S3.I1.i3.p1.3.m3.1.1.1.1.1.2.3.cmml" type="integer" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.2.3">2</cn></apply><ci id="S3.I1.i3.p1.3.m3.1.1.1.1.1.3a.cmml" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S3.I1.i3.p1.3.m3.1.1.1.1.1.3.cmml" xref="S3.I1.i3.p1.3.m3.1.1.1.1.1.3">max_len</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.3.m3.1c">O(n^{2}/\texttt{max\_len})</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.3.m3.1d">italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / max_len )</annotation></semantics></math> by employing a monotonic queue for sliding-window minimum calculations. This allows for efficient computation across most code files. The pseudocode of the optimized dynamic programming algorithm is shown in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#alg1" title="In 3.2 AST-Aware Segmentation ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Algorithm</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>. See <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.SS2" title="A.2 More about AST-Aware Segmentation ‣ Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">A.2</span></a> for details about complexity calculations.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1">The algorithm outputs the partition associated with <span class="ltx_text ltx_font_typewriter" id="S3.I1.i4.p1.1.1">dp[k_min, n]</span>, where <math alttext="\texttt{k\_min}=\arg\min_{k}(\texttt{dp}[k,n])" class="ltx_Math" display="inline" id="S3.I1.i4.p1.1.m1.4"><semantics id="S3.I1.i4.p1.1.m1.4a"><mrow id="S3.I1.i4.p1.1.m1.4.4" xref="S3.I1.i4.p1.1.m1.4.4.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.I1.i4.p1.1.m1.4.4.4" xref="S3.I1.i4.p1.1.m1.4.4.4a.cmml">k_min</mtext><mo id="S3.I1.i4.p1.1.m1.4.4.3" xref="S3.I1.i4.p1.1.m1.4.4.3.cmml">=</mo><mrow id="S3.I1.i4.p1.1.m1.4.4.2" xref="S3.I1.i4.p1.1.m1.4.4.2.cmml"><mi id="S3.I1.i4.p1.1.m1.4.4.2.3" xref="S3.I1.i4.p1.1.m1.4.4.2.3.cmml">arg</mi><mo id="S3.I1.i4.p1.1.m1.4.4.2a" lspace="0.167em" xref="S3.I1.i4.p1.1.m1.4.4.2.cmml">⁡</mo><mrow id="S3.I1.i4.p1.1.m1.4.4.2.2.2" xref="S3.I1.i4.p1.1.m1.4.4.2.2.3.cmml"><msub id="S3.I1.i4.p1.1.m1.3.3.1.1.1.1" xref="S3.I1.i4.p1.1.m1.3.3.1.1.1.1.cmml"><mi id="S3.I1.i4.p1.1.m1.3.3.1.1.1.1.2" xref="S3.I1.i4.p1.1.m1.3.3.1.1.1.1.2.cmml">min</mi><mi id="S3.I1.i4.p1.1.m1.3.3.1.1.1.1.3" xref="S3.I1.i4.p1.1.m1.3.3.1.1.1.1.3.cmml">k</mi></msub><mo id="S3.I1.i4.p1.1.m1.4.4.2.2.2a" xref="S3.I1.i4.p1.1.m1.4.4.2.2.3.cmml">⁡</mo><mrow id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2" xref="S3.I1.i4.p1.1.m1.4.4.2.2.3.cmml"><mo id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.2" stretchy="false" xref="S3.I1.i4.p1.1.m1.4.4.2.2.3.cmml">(</mo><mrow id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.2" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.2a.cmml">dp</mtext><mo id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.1" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.1.cmml">⁢</mo><mrow id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.3.2" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.3.1.cmml"><mo id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.3.2.1" stretchy="false" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.3.1.cmml">[</mo><mi id="S3.I1.i4.p1.1.m1.1.1" xref="S3.I1.i4.p1.1.m1.1.1.cmml">k</mi><mo id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.3.2.2" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.3.1.cmml">,</mo><mi id="S3.I1.i4.p1.1.m1.2.2" xref="S3.I1.i4.p1.1.m1.2.2.cmml">n</mi><mo id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.3.2.3" stretchy="false" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.3.1.cmml">]</mo></mrow></mrow><mo id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.3" stretchy="false" xref="S3.I1.i4.p1.1.m1.4.4.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i4.p1.1.m1.4b"><apply id="S3.I1.i4.p1.1.m1.4.4.cmml" xref="S3.I1.i4.p1.1.m1.4.4"><eq id="S3.I1.i4.p1.1.m1.4.4.3.cmml" xref="S3.I1.i4.p1.1.m1.4.4.3"></eq><ci id="S3.I1.i4.p1.1.m1.4.4.4a.cmml" xref="S3.I1.i4.p1.1.m1.4.4.4"><mtext class="ltx_mathvariant_monospace" id="S3.I1.i4.p1.1.m1.4.4.4.cmml" xref="S3.I1.i4.p1.1.m1.4.4.4">k_min</mtext></ci><apply id="S3.I1.i4.p1.1.m1.4.4.2.cmml" xref="S3.I1.i4.p1.1.m1.4.4.2"><arg id="S3.I1.i4.p1.1.m1.4.4.2.3.cmml" xref="S3.I1.i4.p1.1.m1.4.4.2.3"></arg><apply id="S3.I1.i4.p1.1.m1.4.4.2.2.3.cmml" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2"><apply id="S3.I1.i4.p1.1.m1.3.3.1.1.1.1.cmml" xref="S3.I1.i4.p1.1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.I1.i4.p1.1.m1.3.3.1.1.1.1.1.cmml" xref="S3.I1.i4.p1.1.m1.3.3.1.1.1.1">subscript</csymbol><min id="S3.I1.i4.p1.1.m1.3.3.1.1.1.1.2.cmml" xref="S3.I1.i4.p1.1.m1.3.3.1.1.1.1.2"></min><ci id="S3.I1.i4.p1.1.m1.3.3.1.1.1.1.3.cmml" xref="S3.I1.i4.p1.1.m1.3.3.1.1.1.1.3">𝑘</ci></apply><apply id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.cmml" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1"><times id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.1.cmml" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.1"></times><ci id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.2a.cmml" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.2"><mtext class="ltx_mathvariant_monospace" id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.2.cmml" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.2">dp</mtext></ci><interval closure="closed" id="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.3.1.cmml" xref="S3.I1.i4.p1.1.m1.4.4.2.2.2.2.1.3.2"><ci id="S3.I1.i4.p1.1.m1.1.1.cmml" xref="S3.I1.i4.p1.1.m1.1.1">𝑘</ci><ci id="S3.I1.i4.p1.1.m1.2.2.cmml" xref="S3.I1.i4.p1.1.m1.2.2">𝑛</ci></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i4.p1.1.m1.4c">\texttt{k\_min}=\arg\min_{k}(\texttt{dp}[k,n])</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i4.p1.1.m1.4d">k_min = roman_arg roman_min start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( dp [ italic_k , italic_n ] )</annotation></semantics></math>, as the most optimal partition.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> Dynamic Programming in AST-Aware Segmentation</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_figure_panel undefined" id="alg1.3">{minted}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="alg1.4">[linenos,xleftmargin=20pt,fontsize=]python
# n: the length of the code file
# (number of tokens)
# m: the max number of segments;
# approximately n / max_len
for k in range(1, m + 1):
q = Queue() # double ended queue
for i in range(1, n + 1):
while (q.nonempty() and
q.left() ¡ i - max_len):
# pop indices before i - max_len
q.pop_left()
while (q.nonempty() and
dp[k-1, q.right()] ¿ dp[k-1, i-1]):
# maintain monotonicity of values
q.pop_right()
q.push_right(i - 1) # push i - 1
best_j = q.left()
# guaranteed to have the smallest value
prev[k, i] = best_j
dp[k, i] = cost[i] + dp[k - 1, best_j]</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1">In comparing AST-Aware Segmentation with Greedy Segmentation—using the example in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.F2" title="In 3.2 AST-Aware Segmentation ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>—we find that the former presents more coherent code segments to the model during pretraining. Conversely, the latter introduces noisy partial expressions near partition boundaries. Consequently, AST-Aware Segmentation not only optimizes the pretraining process but also reduces the mismatch between pretraining and downstream tasks, which often involve complete function definitions as inputs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Pretraining with Span Corruption</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.p1">
<span class="ltx_ERROR undefined" id="S3.SS3.p1.1">\nolbreaks</span>
<p class="ltx_p" id="S3.SS3.p1.2">AST-T5’s pretraining is based on <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.2.1">span corruption</span>, a well-established method for pretraining transformer encoder-decoder models&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Raffel et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib32" title="">2020</a>)</cite>. In this approach, 15% of the input tokens are randomly masked and replaced by unique “sentinel” tokens, distinct within each example. Each unique sentinel token is associated with a specific ID and added to the model’s vocabulary.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">During pretraining, the encoder processes the corrupted input sequence. The decoder’s objective is to reconstruct the dropped-out tokens based on the encoder’s output representations. Specifically, the target sequence consists of the masked spans of tokens, demarcated by their corresponding sentinel tokens. This framework effectively trains the model to recover the original text from a corrupted input. <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S1.F1" title="In 1 Introduction ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a> (Left) illustrates an example of the input-output pair for span corruption.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>AST-Aware Subtree Corruption</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg2.2.1.1">Algorithm 2</span> </span> Subtree Selection in AST-Aware Subtree Corruption</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_figure_panel undefined" id="alg2.3">{minted}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="alg2.4">[linenos,xleftmargin=20pt,fontsize=]python
def mask_subtree(t: ASTNode, m: int):
”””mask m tokens in subtree t”””
ordered_children = []
m_remaining = m
# distribute m tokens among children of t
for child in t.children:
# theta: a hyperparameter to control
# masking granularity
if child.size ¿ theta:
# same mask ratio as the current subtree
m_child = m * (child.size / t.size)
mask_subtree(child, m_child) # recurse
m_remaining -= m_child
else:
ordered_children.append(child)
weighted_shuffle(ordered_children)
# greedy allocation of remaining mask quota
for child in ordered_children:
m_child = min(m_remaining, child.size)
mask_subtree(child, m_child)
m_remaining -= m_child</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS4.p1">
<span class="ltx_ERROR undefined" id="S3.SS4.p1.1">\nolbreaks</span>
<p class="ltx_p" id="S3.SS4.p1.2">AST-T5 augments the traditional span corruption paradigm by incorporating AST-awareness. Rather than arbitrarily masking consecutive token spans, <span class="ltx_ERROR undefined" id="S3.SS4.p1.2.1">\nolbreaks</span>AST-T5 masks code spans corresponding to AST subtrees, ranging from individual expressions to entire function bodies.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Subtree Masking.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p1.1">We use a recursive algorithm, outlined in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#alg2" title="In 3.4 AST-Aware Subtree Corruption ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Algorithm</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, to traverse the AST and select subtrees for masking. The algorithm aims to fulfill two goals:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS4.SSS0.Px1.p2">
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1">Introduce sufficient randomness across training epochs to enhance generalization.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1">Control the masking granularity via a tunable hyperparameter <math alttext="\theta" class="ltx_Math" display="inline" id="S3.I2.i2.p1.1.m1.1"><semantics id="S3.I2.i2.p1.1.m1.1a"><mi id="S3.I2.i2.p1.1.m1.1.1" xref="S3.I2.i2.p1.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.1.m1.1b"><ci id="S3.I2.i2.p1.1.m1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.1.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i2.p1.1.m1.1d">italic_θ</annotation></semantics></math> (named <span class="ltx_text ltx_font_typewriter" id="S3.I2.i2.p1.1.1">theta</span> in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#alg2" title="In 3.4 AST-Aware Subtree Corruption ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Algorithm</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, Line 9).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS4.SSS0.Px1.p3">
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p3.8">The “mask quota” <math alttext="m" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p3.1.m1.1"><semantics id="S3.SS4.SSS0.Px1.p3.1.m1.1a"><mi id="S3.SS4.SSS0.Px1.p3.1.m1.1.1" xref="S3.SS4.SSS0.Px1.p3.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p3.1.m1.1b"><ci id="S3.SS4.SSS0.Px1.p3.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p3.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p3.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p3.1.m1.1d">italic_m</annotation></semantics></math> denotes the number of tokens to be masked in a subtree rooted at node <math alttext="t" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p3.2.m2.1"><semantics id="S3.SS4.SSS0.Px1.p3.2.m2.1a"><mi id="S3.SS4.SSS0.Px1.p3.2.m2.1.1" xref="S3.SS4.SSS0.Px1.p3.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p3.2.m2.1b"><ci id="S3.SS4.SSS0.Px1.p3.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px1.p3.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p3.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p3.2.m2.1d">italic_t</annotation></semantics></math>. The size of a subtree corresponds to the number of tokens it encompasses, derived from the cumulative sizes of its children. For larger subtrees that exceed the size threshold <math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p3.3.m3.1"><semantics id="S3.SS4.SSS0.Px1.p3.3.m3.1a"><mi id="S3.SS4.SSS0.Px1.p3.3.m3.1.1" xref="S3.SS4.SSS0.Px1.p3.3.m3.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p3.3.m3.1b"><ci id="S3.SS4.SSS0.Px1.p3.3.m3.1.1.cmml" xref="S3.SS4.SSS0.Px1.p3.3.m3.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p3.3.m3.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p3.3.m3.1d">italic_θ</annotation></semantics></math>, masking is applied recursively (Lines 9-13). Meanwhile, smaller subtrees undergo a weighted shuffle, and the quota <math alttext="m" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p3.4.m4.1"><semantics id="S3.SS4.SSS0.Px1.p3.4.m4.1a"><mi id="S3.SS4.SSS0.Px1.p3.4.m4.1.1" xref="S3.SS4.SSS0.Px1.p3.4.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p3.4.m4.1b"><ci id="S3.SS4.SSS0.Px1.p3.4.m4.1.1.cmml" xref="S3.SS4.SSS0.Px1.p3.4.m4.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p3.4.m4.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p3.4.m4.1d">italic_m</annotation></semantics></math> is then apportioned among <math alttext="t" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p3.5.m5.1"><semantics id="S3.SS4.SSS0.Px1.p3.5.m5.1a"><mi id="S3.SS4.SSS0.Px1.p3.5.m5.1.1" xref="S3.SS4.SSS0.Px1.p3.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p3.5.m5.1b"><ci id="S3.SS4.SSS0.Px1.p3.5.m5.1.1.cmml" xref="S3.SS4.SSS0.Px1.p3.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p3.5.m5.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p3.5.m5.1d">italic_t</annotation></semantics></math>’s children in a greedy fashion according to the shuffled order (Lines 17-21). The weights for shuffling are determined by a heuristic function on the size of each child, such that masking probabilities are distributed uniformly across leaf nodes. To create a subtree mask for an AST rooted at <math alttext="t" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p3.6.m6.1"><semantics id="S3.SS4.SSS0.Px1.p3.6.m6.1a"><mi id="S3.SS4.SSS0.Px1.p3.6.m6.1.1" xref="S3.SS4.SSS0.Px1.p3.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p3.6.m6.1b"><ci id="S3.SS4.SSS0.Px1.p3.6.m6.1.1.cmml" xref="S3.SS4.SSS0.Px1.p3.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p3.6.m6.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p3.6.m6.1d">italic_t</annotation></semantics></math> with a mask ratio <math alttext="r" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p3.7.m7.1"><semantics id="S3.SS4.SSS0.Px1.p3.7.m7.1a"><mi id="S3.SS4.SSS0.Px1.p3.7.m7.1.1" xref="S3.SS4.SSS0.Px1.p3.7.m7.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p3.7.m7.1b"><ci id="S3.SS4.SSS0.Px1.p3.7.m7.1.1.cmml" xref="S3.SS4.SSS0.Px1.p3.7.m7.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p3.7.m7.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p3.7.m7.1d">italic_r</annotation></semantics></math> (e.g., 15% or 25%), one can use <math alttext="\texttt{mask\_subtree}(t,\lfloor|t|\cdot r\rfloor)" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p3.8.m8.3"><semantics id="S3.SS4.SSS0.Px1.p3.8.m8.3a"><mrow id="S3.SS4.SSS0.Px1.p3.8.m8.3.3" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.3" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.3a.cmml">mask_subtree</mtext><mo id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.2" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.2.cmml">⁢</mo><mrow id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.2.cmml"><mo id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.2" stretchy="false" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.2.cmml">(</mo><mi id="S3.SS4.SSS0.Px1.p3.8.m8.2.2" xref="S3.SS4.SSS0.Px1.p3.8.m8.2.2.cmml">t</mi><mo id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.3" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.2.cmml">,</mo><mrow id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.2.cmml"><mo id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.2" stretchy="false" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.2.1.cmml">⌊</mo><mrow id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.cmml"><mrow id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.2.2" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.2.1.cmml"><mo id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.2.2.1" stretchy="false" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.2.1.1.cmml">|</mo><mi id="S3.SS4.SSS0.Px1.p3.8.m8.1.1" xref="S3.SS4.SSS0.Px1.p3.8.m8.1.1.cmml">t</mi><mo id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.2.2.2" rspace="0.055em" stretchy="false" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.2.1.1.cmml">|</mo></mrow><mo id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.1" rspace="0.222em" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.1.cmml">⋅</mo><mi id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.3" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.3.cmml">r</mi></mrow><mo id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.3" stretchy="false" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.2.1.cmml">⌋</mo></mrow><mo id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.4" stretchy="false" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p3.8.m8.3b"><apply id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3"><times id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.2.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.2"></times><ci id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.3a.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.3"><mtext class="ltx_mathvariant_monospace" id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.3.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.3">mask_subtree</mtext></ci><interval closure="open" id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.2.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1"><ci id="S3.SS4.SSS0.Px1.p3.8.m8.2.2.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.2.2">𝑡</ci><apply id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1"><floor id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.2.1.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.2"></floor><apply id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1"><ci id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.1">⋅</ci><apply id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.2.1.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.2.2"><abs id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.2.1.1.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.2.2.1"></abs><ci id="S3.SS4.SSS0.Px1.p3.8.m8.1.1.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.1.1">𝑡</ci></apply><ci id="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p3.8.m8.3.3.1.1.1.1.1.3">𝑟</ci></apply></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p3.8.m8.3c">\texttt{mask\_subtree}(t,\lfloor|t|\cdot r\rfloor)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p3.8.m8.3d">mask_subtree ( italic_t , ⌊ | italic_t | ⋅ italic_r ⌋ )</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS4.SSS0.Px1.p4">
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p4.5">The parameter <math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p4.1.m1.1"><semantics id="S3.SS4.SSS0.Px1.p4.1.m1.1a"><mi id="S3.SS4.SSS0.Px1.p4.1.m1.1.1" xref="S3.SS4.SSS0.Px1.p4.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p4.1.m1.1b"><ci id="S3.SS4.SSS0.Px1.p4.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p4.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p4.1.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p4.1.m1.1d">italic_θ</annotation></semantics></math> controls the granularity of masking. For example, with <math alttext="\theta=5" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p4.2.m2.1"><semantics id="S3.SS4.SSS0.Px1.p4.2.m2.1a"><mrow id="S3.SS4.SSS0.Px1.p4.2.m2.1.1" xref="S3.SS4.SSS0.Px1.p4.2.m2.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p4.2.m2.1.1.2" xref="S3.SS4.SSS0.Px1.p4.2.m2.1.1.2.cmml">θ</mi><mo id="S3.SS4.SSS0.Px1.p4.2.m2.1.1.1" xref="S3.SS4.SSS0.Px1.p4.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS4.SSS0.Px1.p4.2.m2.1.1.3" xref="S3.SS4.SSS0.Px1.p4.2.m2.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p4.2.m2.1b"><apply id="S3.SS4.SSS0.Px1.p4.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px1.p4.2.m2.1.1"><eq id="S3.SS4.SSS0.Px1.p4.2.m2.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p4.2.m2.1.1.1"></eq><ci id="S3.SS4.SSS0.Px1.p4.2.m2.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p4.2.m2.1.1.2">𝜃</ci><cn id="S3.SS4.SSS0.Px1.p4.2.m2.1.1.3.cmml" type="integer" xref="S3.SS4.SSS0.Px1.p4.2.m2.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p4.2.m2.1c">\theta=5</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p4.2.m2.1d">italic_θ = 5</annotation></semantics></math>, the algorithm has a high probability to mask individual tokens and short expressions. As <math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p4.3.m3.1"><semantics id="S3.SS4.SSS0.Px1.p4.3.m3.1a"><mi id="S3.SS4.SSS0.Px1.p4.3.m3.1.1" xref="S3.SS4.SSS0.Px1.p4.3.m3.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p4.3.m3.1b"><ci id="S3.SS4.SSS0.Px1.p4.3.m3.1.1.cmml" xref="S3.SS4.SSS0.Px1.p4.3.m3.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p4.3.m3.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p4.3.m3.1d">italic_θ</annotation></semantics></math> increases to 20, the algorithm is more likely to mask larger constructs such as statements. When <math alttext="\theta=100" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p4.4.m4.1"><semantics id="S3.SS4.SSS0.Px1.p4.4.m4.1a"><mrow id="S3.SS4.SSS0.Px1.p4.4.m4.1.1" xref="S3.SS4.SSS0.Px1.p4.4.m4.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p4.4.m4.1.1.2" xref="S3.SS4.SSS0.Px1.p4.4.m4.1.1.2.cmml">θ</mi><mo id="S3.SS4.SSS0.Px1.p4.4.m4.1.1.1" xref="S3.SS4.SSS0.Px1.p4.4.m4.1.1.1.cmml">=</mo><mn id="S3.SS4.SSS0.Px1.p4.4.m4.1.1.3" xref="S3.SS4.SSS0.Px1.p4.4.m4.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p4.4.m4.1b"><apply id="S3.SS4.SSS0.Px1.p4.4.m4.1.1.cmml" xref="S3.SS4.SSS0.Px1.p4.4.m4.1.1"><eq id="S3.SS4.SSS0.Px1.p4.4.m4.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p4.4.m4.1.1.1"></eq><ci id="S3.SS4.SSS0.Px1.p4.4.m4.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p4.4.m4.1.1.2">𝜃</ci><cn id="S3.SS4.SSS0.Px1.p4.4.m4.1.1.3.cmml" type="integer" xref="S3.SS4.SSS0.Px1.p4.4.m4.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p4.4.m4.1c">\theta=100</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p4.4.m4.1d">italic_θ = 100</annotation></semantics></math>, the probability increases for masking structures like loops or entire function bodies. To foster diverse training scenarios, <math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p4.5.m5.1"><semantics id="S3.SS4.SSS0.Px1.p4.5.m5.1a"><mi id="S3.SS4.SSS0.Px1.p4.5.m5.1.1" xref="S3.SS4.SSS0.Px1.p4.5.m5.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p4.5.m5.1b"><ci id="S3.SS4.SSS0.Px1.p4.5.m5.1.1.cmml" xref="S3.SS4.SSS0.Px1.p4.5.m5.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p4.5.m5.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p4.5.m5.1d">italic_θ</annotation></semantics></math> is randomly sampled within a predefined range (e.g., 5 to 100) for each training example. This allows the pretraining framework to inherently accommodate tasks as varied as single-token completion to full function body generation from a given signature.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS4.SSS0.Px1.p5">
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p5.1">The subtree masking strategy is the primary distinction between our AST-Aware Subtree Corruption and the Vanilla T5 Span Corruption, as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S1.F1" title="In 1 Introduction ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>. While conventional T5 variants mask random token spans, with an average span length of 3&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Raffel et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib32" title="">2020</a>)</cite> and neglecting code structures, our method targets the masking of AST subtrees, potentially encompassing up to 100 tokens. This equips AST-T5 for generation of various code structures coherently.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Pretraining Objective.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px2.p1.1">Except for the strategy used to select masked tokens and the segmentation strategy described in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.SS2" title="3.2 AST-Aware Segmentation ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2</span></a>
, our approach adheres to the workflow described in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.SS3" title="3.3 Pretraining with Span Corruption ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.3</span></a>. Once subtrees are selected for masking and replaced with sentinel tokens, the encoder processes this modified input. Subsequently, the decoder is tasked with reconstructing the original tokens within the masked subtrees. A side-by-side comparison between our approach and the Vanilla Span Corruption in T5 is presented in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S1.F1" title="In 1 Introduction ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Setup</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Model Architecture.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<span class="ltx_ERROR undefined" id="S4.SS0.SSS0.Px1.p1.2">\nolbreaks</span>
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">AST-T5 has an architecture similar to T5<math alttext="{}_{\textsc{Base}}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px1.p1.1.m1.1a"><msub id="S4.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.1.m1.1.1a" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1a.cmml">Base</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1"><ci id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1a.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1">Base</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.1.m1.1c">{}_{\textsc{Base}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px1.p1.1.m1.1d">start_FLOATSUBSCRIPT Base end_FLOATSUBSCRIPT</annotation></semantics></math>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Raffel et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib32" title="">2020</a>)</cite>, comprising a 12-layer encoder and a 12-layer decoder, where each layer has 768 dimensions and 12 attention heads. In total, the model has 277M parameters.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Pretraining.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<span class="ltx_ERROR undefined" id="S4.SS0.SSS0.Px2.p1.1">\nolbreaks</span>
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.2">AST-T5 is pretrained on a subset of The Stack Dedup corpus&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Kocetkov et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib21" title="">2022</a>)</cite>, a near-deduplicated version of The Stack—a 3.1TB collection of permissively licensed source code from GitHub cutoff at April 2022, spanning 358 programming languages. For our experiments, <span class="ltx_ERROR undefined" id="S4.SS0.SSS0.Px2.p1.2.1">\nolbreaks</span>AST-T5’s training involves Python, Java, C, C++, C#, Markdown, and reStructuredText subsets, comprising a 588GB dataset with 93M code and natural language files.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p2.1">Each file is first parsed into its AST using the Tree-Sitter multi-language parser, and then tokenized with byte-level Byte-Pair Encoding (BPE) using a byte-level BPE token vocabulary.
Following AST-Aware Segmentation, these files are partitioned into chunks of 1,024 tokens. Our model is pretrained using the AST-Aware Subtree Corruption objective for 524 billion tokens (1,024 tokens per sequence, 1,024 sequences per batch, and 500k steps). For each training example, we apply AST-Aware Subtree Corruption of it is code, or apply Vanilla T5 Span Corruption of it is natural language. For code, the threshold, <math alttext="\theta" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p2.1.m1.1"><semantics id="S4.SS0.SSS0.Px2.p2.1.m1.1a"><mi id="S4.SS0.SSS0.Px2.p2.1.m1.1.1" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p2.1.m1.1b"><ci id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p2.1.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p2.1.m1.1d">italic_θ</annotation></semantics></math>, is uniformly sampled from 5 to 100. For text, the length of each masked span is uniformly sampled from 1 to 10. Pretraining uses PyTorch, Fairseq<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/facebookresearch/fairseq" title="">https://github.com/facebookresearch/fairseq</a></span></span></span> and FlashAttention&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib14" title="">2022</a>)</cite> and is conducted on 8 nodes, each with 8x NVIDIA A100 40GB GPUs. Further pretraining hyperparameters are detailed in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.SS3" title="A.3 Pretraining Hyperparameters ‣ Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">A.3</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Evaluation.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.1">We evaluate <span class="ltx_ERROR undefined" id="S4.SS0.SSS0.Px3.p1.1.1">\nolbreaks</span>AST-T5 across three types of tasks: text-to-code generation, code-to-code transpilation, and code understanding (classification). Our evaluation encompasses tasks from the CodeXGLUE meta-benchmark&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib27" title="">2021</a>)</cite> and also includes HumanEval&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib10" title="">2021a</a>)</cite> and MBPP&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Austin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib5" title="">2021</a>)</cite>. Specifically, for text-to-code generation, we assess performance using HumanEval, MBPP, and Concode&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Iyer et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib19" title="">2018</a>)</cite>; for transpilation, we use CodeXGLUE Java-C# and Bugs2Fix&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Tufano et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib41" title="">2019</a>)</cite> for evaluation; and for understanding, we use BigCloneBench&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Svajlenko et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib38" title="">2014</a>)</cite> and the Defect Detection task proposed by <cite class="ltx_cite ltx_citemacro_citet">Zhou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib46" title="">2019</a>)</cite>. Detailed metrics and statistics of these datasets are provided in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S4.T1" title="In Evaluation. ‣ 4 Experimental Setup ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.4.2.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S4.T1.2.1" style="font-size:90%;">Overview of our evaluation benchmarks about test set size, task type, and evaluation metric for each task. “Generation” tasks involve mapping natural language to code, “Transpilation” tasks involve translating code from one programming language to another, and “Understanding” tasks involve classifying code into categorical labels. For MBPP, we follow <cite class="ltx_cite ltx_citemacro_citet">Nijkamp et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib29" title="">2023b</a>)</cite> and evaluate our model on the entire “sanitized” subset without few-shot prompts. For evaluation metrics, “Pass@1” indicates code execution on unit-tests provided in the benchmark using a single generated code per example, with reported pass rates. “EM” (Exact Match) evaluates textual equivalence without execution by comparing two canonicalized code pieces. “Acc” means accuracy in classification tasks. We omit “BLEU scores” because high BLEU values (<math alttext="&gt;" class="ltx_Math" display="inline" id="S4.T1.2.1.m1.1"><semantics id="S4.T1.2.1.m1.1b"><mo id="S4.T1.2.1.m1.1.1" xref="S4.T1.2.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.1.m1.1c"><gt id="S4.T1.2.1.m1.1.1.cmml" xref="S4.T1.2.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.1.m1.1d">&gt;</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.1.m1.1e">&gt;</annotation></semantics></math> 50) can still correspond to unexecutable or significantly flawed code&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib27" title="">2021</a>)</cite>, which is not useful in real-world applications. We also discuss evaluation results using the CodeBLEU&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ren et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib33" title="">2020</a>)</cite> metric in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.SS6" title="A.6 Evaluation Results in CodeBLEU ‣ Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">A.6</span></a>.</span></figcaption>
<br class="ltx_break">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.5" style="width:234.9pt;height:136.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-6.2pt,3.6pt) scale(0.95,0.95) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.5.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T1.5.1.1.1.1"></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T1.5.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.2.1">Size</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.5.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.3.1">Type</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.5.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.4.1">Metric</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.5.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.5.1.2.1.1">HumanEval</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="S4.T1.5.1.2.1.2">164</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.5.1.2.1.3">Generation</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.5.1.2.1.4">Pass@1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.5.1.3.2.1">MBPP</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T1.5.1.3.2.2">427</th>
<td class="ltx_td ltx_align_left" id="S4.T1.5.1.3.2.3">Generation</td>
<td class="ltx_td ltx_align_left" id="S4.T1.5.1.3.2.4">Pass@1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.5.1.4.3.1">Concode</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T1.5.1.4.3.2">2,000</th>
<td class="ltx_td ltx_align_left" id="S4.T1.5.1.4.3.3">Generation</td>
<td class="ltx_td ltx_align_left" id="S4.T1.5.1.4.3.4">EM</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.5.1.5.4.1">Bugs2Fix</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T1.5.1.5.4.2">12,379</th>
<td class="ltx_td ltx_align_left" id="S4.T1.5.1.5.4.3">Transpilation</td>
<td class="ltx_td ltx_align_left" id="S4.T1.5.1.5.4.4">EM</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.5.1.6.5.1">Java-C#</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T1.5.1.6.5.2">1,000</th>
<td class="ltx_td ltx_align_left" id="S4.T1.5.1.6.5.3">Transpilation</td>
<td class="ltx_td ltx_align_left" id="S4.T1.5.1.6.5.4">EM</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.5.1.7.6.1">BigCloneBench</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T1.5.1.7.6.2">415,416</th>
<td class="ltx_td ltx_align_left" id="S4.T1.5.1.7.6.3">Understanding</td>
<td class="ltx_td ltx_align_left" id="S4.T1.5.1.7.6.4">F1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.5.1.8.7.1">Defect Detect</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb" id="S4.T1.5.1.8.7.2">27,318</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.5.1.8.7.3">Understanding</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.5.1.8.7.4">Acc</td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p2.1">We finetune <span class="ltx_ERROR undefined" id="S4.SS0.SSS0.Px3.p2.1.1">\nolbreaks</span>AST-T5 on the training datasets of all downstream tasks, adhering to the methodology by <cite class="ltx_cite ltx_citemacro_citet">Raffel et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib32" title="">2020</a>)</cite>. For the HumanEval task, which lacks its own training dataset, we use CodeSearchNet&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Husain et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib18" title="">2020</a>)</cite>, aligning with the approach of <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib44" title="">2023</a>)</cite>. The prompt templates for finetuning are constructed using the PromptSource framework&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Bach et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib6" title="">2022</a>)</cite>. The finetuning takes 50k steps, with the peak learning rate set at 10% of the pretraining learning rate. All other hyperparameters from pretraining are retained without further adjustments, and we train only one finetuned model. During inference, rank classification is employed for code understanding tasks and beam search is used for generative tasks, following <cite class="ltx_cite ltx_citemacro_citet">Sanh et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib36" title="">2021</a>)</cite>. For CodeXGLUE, we evaluate our model on the test set using five prompt templates for each task and report the average performance; for HumanEval and MBPP, we evaluate the top-1 generated output from beam search.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Baselines.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p1.1">We first benchmark <span class="ltx_ERROR undefined" id="S4.SS0.SSS0.Px4.p1.1.1">\nolbreaks</span>AST-T5 against our own T5 baselines to ensure a controlled comparison. All models share identical Transformer architectures, pretraining data, and computational settings, differing only in the use of AST-Aware Segmentation and Subtree Corruption techniques by <span class="ltx_ERROR undefined" id="S4.SS0.SSS0.Px4.p1.1.2">\nolbreaks</span>AST-T5. This setup directly evaluates the efficacy of our proposed methods.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p2">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p2.1">We further benchmark <span class="ltx_ERROR undefined" id="S4.SS0.SSS0.Px4.p2.1.1">\nolbreaks</span>AST-T5 against other language models for code-related tasks. These include decoder-only models such as the GPT variants&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Brown et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib9" title="">2020</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib10" title="">2021a</a>; Wang &amp; Komatsuzaki, <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib42" title="">2021</a>; Black et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib8" title="">2021</a>)</cite>, PaLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chowdhery et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib13" title="">2022</a>)</cite>, InCoder&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Fried et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib16" title="">2023</a>)</cite>, and LLaMa&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib40" title="">2023</a>)</cite>. We also compare with encoder-decoder models, including PLBART&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ahmad et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib1" title="">2021</a>)</cite>, CodeT5&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib43" title="">2021</a>)</cite>, StructCoder&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Tipirneni et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib39" title="">2023</a>)</cite>, and CodeT5+&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib44" title="">2023</a>)</cite>. Notably, CodeT5<math alttext="{}_{\textsc{Base}}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p2.1.m1.1"><semantics id="S4.SS0.SSS0.Px4.p2.1.m1.1a"><msub id="S4.SS0.SSS0.Px4.p2.1.m1.1.1" xref="S4.SS0.SSS0.Px4.p2.1.m1.1.1.cmml"><mi id="S4.SS0.SSS0.Px4.p2.1.m1.1.1a" xref="S4.SS0.SSS0.Px4.p2.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS0.SSS0.Px4.p2.1.m1.1.1.1" xref="S4.SS0.SSS0.Px4.p2.1.m1.1.1.1a.cmml">Base</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p2.1.m1.1b"><apply id="S4.SS0.SSS0.Px4.p2.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p2.1.m1.1.1"><ci id="S4.SS0.SSS0.Px4.p2.1.m1.1.1.1a.cmml" xref="S4.SS0.SSS0.Px4.p2.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S4.SS0.SSS0.Px4.p2.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS0.SSS0.Px4.p2.1.m1.1.1.1">Base</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p2.1.m1.1c">{}_{\textsc{Base}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p2.1.m1.1d">start_FLOATSUBSCRIPT Base end_FLOATSUBSCRIPT</annotation></semantics></math> and CodeT5+ (220M) closely resemble our model in terms of architecture and size, but <span class="ltx_ERROR undefined" id="S4.SS0.SSS0.Px4.p2.1.2">\nolbreaks</span>AST-T5 distinguishes itself with its AST-Aware pretraining techniques.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Evaluation Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T2.2.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S5.T2.3.2" style="font-size:90%;">Performance comparison of various pretraining configurations for downstream tasks. Each row represents a sequential modification applied to the model in the previous row. Metrics include “Pass@1” rate for HumanEval, “Exact Match” rate for CONCODE, Bugs2Fix (for “Small” and “Medium” code lengths splits), and Java-C# transpilation (both Java-to-C# and C#-to-Java). F1 score is used for Clone Detection, and Accuracy for Defect Detection, consistent with prior studies.</span></figcaption>
<br class="ltx_break">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.4" style="width:428.6pt;height:119.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.3pt,3.1pt) scale(0.95,0.95) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.4.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T2.4.1.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T2.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.1.1.2.1">Generation</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T2.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.1.1.3.1">Transpilation</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T2.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.1.1.4.1">Understanding</span></td>
<td class="ltx_td ltx_border_tt" id="S5.T2.4.1.1.1.5"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.2.2.1.1">Pretraining Config</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.2.2.2.1">HumanEval</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.2.2.3.1">Concode</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.2.2.4.1">Bugs2Fix</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.2.2.5.1">Java-C#</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.2.2.6"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.2.2.6.1">Clone</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.2.2.7"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.2.2.7.1">Defect</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.2.2.8"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.2.2.8.1">Avg</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.4.1.3.3.1">T5</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.3.3.2">5.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.3.3.3">18.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.3.3.4">21.2/13.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.3.3.5">65.5/68.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.3.3.6">96.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.3.3.7">64.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.4.1.3.3.8">44.2</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.1.4.4.1">+ AST. Segmentation</th>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.4.4.2">7.2</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.4.4.3">20.2</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.4.4.4">22.5/15.1</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.4.4.5">66.3/69.3</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.4.4.6">98.3</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.4.4.7">65.9</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.4.4.8">45.7</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.1.5.5.1">+ AST. Subtree Corrupt</th>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.5.5.2">9.6</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.5.5.3">22.1</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.5.5.4">23.3/<span class="ltx_text ltx_font_bold" id="S5.T2.4.1.5.5.4.1">16.5</span>
</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.5.5.5">67.3/72.2</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.5.5.6"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.5.5.6.1">98.6</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.5.5.7"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.5.5.7.1">66.0</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.5.5.8">47.0</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.1.6.6.1">+ Mask 25% (<span class="ltx_ERROR undefined" id="S5.T2.4.1.6.6.1.1">\nolbreaks</span>AST-T5)</th>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.6.6.2">14.0</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.6.6.3"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.6.6.3.1">22.9</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.6.6.4">
<span class="ltx_text ltx_font_bold" id="S5.T2.4.1.6.6.4.1">23.8</span>/16.1</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.6.6.5">
<span class="ltx_text ltx_font_bold" id="S5.T2.4.1.6.6.5.1">68.9</span>/<span class="ltx_text ltx_font_bold" id="S5.T2.4.1.6.6.5.2">72.3</span>
</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.6.6.6"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.6.6.6.1">98.6</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.6.6.7">65.8</td>
<td class="ltx_td ltx_align_right" id="S5.T2.4.1.6.6.8"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.6.6.8.1">47.9</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S5.T2.4.1.7.7.1">+ Mask 50%</th>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S5.T2.4.1.7.7.2"><span class="ltx_text ltx_font_bold" id="S5.T2.4.1.7.7.2.1">14.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S5.T2.4.1.7.7.3">22.0</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S5.T2.4.1.7.7.4">21.9/15.0</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S5.T2.4.1.7.7.5">66.5/70.1</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S5.T2.4.1.7.7.6">97.1</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S5.T2.4.1.7.7.7">64.2</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S5.T2.4.1.7.7.8">46.4</td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we evaluate AST-T5 across multiple benchmarks. First, we analyze the contributions of each component within our AST-aware pretraining framework through controlled experiments. Next, we benchmark AST-T5 against existing models in prior work.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Pretraining Procedure Analysis</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">In this subsection, we analyze the key components that contribute to the pretraining of <span class="ltx_ERROR undefined" id="S5.SS1.p1.1.1">\nolbreaks</span>AST-T5 models. Holding the model architecture, pretraining datasets, and computational environment constant, we sequentially add one component at a time to a T5 baseline trained on code, culminating in our finalized <span class="ltx_ERROR undefined" id="S5.SS1.p1.1.2">\nolbreaks</span>AST-T5 model. <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.T2" title="In 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a> presents the experimental results. These results show that:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">AST-Aware Segmentation enhances code language models.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1">A comparison between the first two rows of <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.T2" title="In 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a> shows that the model trained with AST-Aware Segmentation consistently outperforms the T5 baseline that uses Greedy Segmentation across all tasks. The advantage stems from the fact that AST-Aware Segmentation produces less fragmented and thus less noisy training inputs during pretraining. Given that most downstream tasks present coherent code structures, such as entire function definitions, the consistency upheld by AST-Aware pretraining aligns better with these structures, leading to improved generalization.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">AST-Aware Span Corruption further boosts generation performance.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1">A comparison between the second and third rows of <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.T2" title="In 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a> reveals an improvement when shifting from Vanilla T5 Span Corruption to our AST-Aware Subtree Corruption. This performance gain is especially notable in generation and transpilation tasks. Such enhancements stem from the ability of AST-Aware Subtree Corruption to guide the model in generating code with better coherence and structural integrity.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Increasing masking ratio improves generation performance.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px3.p1.1">The typical span corruption mask ratio in T5 is set at 15%. Increasing this ratio could potentially enhance the model’s generation capabilities, albeit potentially at the expense of understanding tasks. Essentially, a mask ratio of 100% would emulate a GPT-like, decoder-only Transformer. However, in our experiments (last two rows of <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.T2" title="In 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>), we observed that raising the mask ratio from 15% to 25% significantly improved generation capabilities without noticeably compromising performance in understanding tasks. Further analysis shows that increasing the masking ratio to 50% yields only a marginal improvement on HumanEval (from 14.0 to 14.3), while adversely impacting transpilation and understanding tasks. Thus, we settled on a 25% mask ratio for our <span class="ltx_ERROR undefined" id="S5.SS1.SSS0.Px3.p1.1.1">\nolbreaks</span>AST-T5 model.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Main Results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T3.6.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S5.T3.7.2" style="font-size:90%;">Results of <span class="ltx_ERROR undefined" id="S5.T3.7.2.1">\nolbreaks</span>AST-T5 on downstream tasks compared with reported results of established language models. Evaluation metrics align with those in Table 1. Our focus is primarily on models with similar sizes as <span class="ltx_ERROR undefined" id="S5.T3.7.2.2">\nolbreaks</span>AST-T5, specifically the “Base” models (100M to 300M parameters), while comparisons against larger models are depicted in Figure 3. Some models are either encoder-only or decoder-only and are thus not suited for certain tasks. These results are labeled with “<span class="ltx_text" id="S5.T3.7.2.3" style="color:#808080;">N/A</span>” in this table because they are not available in the literature.</span></figcaption>
<br class="ltx_break">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.1.1" style="width:366.4pt;height:152.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.7pt,4.9pt) scale(0.94,0.94) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.1.1.1.2.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T3.1.1.1.2.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S5.T3.1.1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.2.1.2.1">Generation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S5.T3.1.1.1.2.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.2.1.3.1">Transpilation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S5.T3.1.1.1.2.1.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.2.1.4.1">Understanding</span></th>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S5.T3.1.1.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.3.2.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.1.3.2.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.3.2.2.1">HumanEval</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.1.3.2.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.3.2.3.1">Concode</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.1.3.2.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.3.2.4.1">Bugs2Fix</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.1.3.2.5"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.3.2.5.1">Java-C#</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.1.3.2.6"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.3.2.6.1">Clone</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.1.3.2.7"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.3.2.7.1">Defect</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.1.1.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.1.1.1.4.1.1">CodeBERT</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.1.1.1.4.1.2"><span class="ltx_text" id="S5.T3.1.1.1.4.1.2.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.1.1.1.4.1.3"><span class="ltx_text" id="S5.T3.1.1.1.4.1.3.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.1.1.1.4.1.4">16.4 / 5.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.1.1.1.4.1.5">59.0/58.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.1.1.1.4.1.6">96.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.1.1.1.4.1.7">62.1</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.1.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.1.5.2.1">GraphCodeBERT</th>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.5.2.2"><span class="ltx_text" id="S5.T3.1.1.1.5.2.2.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.5.2.3"><span class="ltx_text" id="S5.T3.1.1.1.5.2.3.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.5.2.4">17.3 / 9.1</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.5.2.5">59.4/58.8</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.5.2.6">97.1</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.5.2.7"><span class="ltx_text" id="S5.T3.1.1.1.5.2.7.1" style="color:#808080;">N/A</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.1.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.1.6.3.1">PLBART</th>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.6.3.2"><span class="ltx_text" id="S5.T3.1.1.1.6.3.2.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.6.3.3">18.8</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.6.3.4">19.2 / 9.0</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.6.3.5">64.6/65.0</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.6.3.6">97.2</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.6.3.7">63.2</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.1.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.1.7.4.1">CodeT5</th>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.7.4.2"><span class="ltx_text" id="S5.T3.1.1.1.7.4.2.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.7.4.3">22.3</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.7.4.4">21.6/14.0</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.7.4.5">65.9/66.9</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.7.4.6">97.2</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.7.4.7">65.8</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.1.1.1">CodeT5+<math alttext="{}_{\textsc{Base}}" class="ltx_Math" display="inline" id="S5.T3.1.1.1.1.1.m1.1"><semantics id="S5.T3.1.1.1.1.1.m1.1a"><msub id="S5.T3.1.1.1.1.1.m1.1.1" xref="S5.T3.1.1.1.1.1.m1.1.1.cmml"><mi id="S5.T3.1.1.1.1.1.m1.1.1a" xref="S5.T3.1.1.1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S5.T3.1.1.1.1.1.m1.1.1.1" xref="S5.T3.1.1.1.1.1.m1.1.1.1a.cmml">Base</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.1.m1.1b"><apply id="S5.T3.1.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1"><ci id="S5.T3.1.1.1.1.1.m1.1.1.1a.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S5.T3.1.1.1.1.1.m1.1.1.1.cmml" mathsize="70%" xref="S5.T3.1.1.1.1.1.m1.1.1.1">Base</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.1.m1.1c">{}_{\textsc{Base}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.1.1.m1.1d">start_FLOATSUBSCRIPT Base end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.1.2">12.0</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.1.3"><span class="ltx_text" id="S5.T3.1.1.1.1.3.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.1.4"><span class="ltx_text" id="S5.T3.1.1.1.1.4.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.1.5"><span class="ltx_text" id="S5.T3.1.1.1.1.5.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.1.6">95.2</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.7.1">66.1</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.1.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.1.8.5.1">StructCoder</th>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.8.5.2"><span class="ltx_text" id="S5.T3.1.1.1.8.5.2.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.8.5.3">22.4</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.8.5.4"><span class="ltx_text" id="S5.T3.1.1.1.8.5.4.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.8.5.5">66.9/68.7</td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.8.5.6"><span class="ltx_text" id="S5.T3.1.1.1.8.5.6.1" style="color:#808080;">N/A</span></td>
<td class="ltx_td ltx_align_right" id="S5.T3.1.1.1.8.5.7"><span class="ltx_text" id="S5.T3.1.1.1.8.5.7.1" style="color:#808080;">N/A</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.1.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T3.1.1.1.9.6.1">AST-T5 (Ours)</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T3.1.1.1.9.6.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.9.6.2.1">14.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T3.1.1.1.9.6.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.9.6.3.1">22.9</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T3.1.1.1.9.6.4">
<span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.9.6.4.1">23.8</span>/<span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.9.6.4.2">16.1</span>
</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T3.1.1.1.9.6.5">
<span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.9.6.5.1">68.9</span>/<span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.9.6.5.2">72.3</span>
</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T3.1.1.1.9.6.6"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.9.6.6.1">98.6</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T3.1.1.1.9.6.7">65.8</td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S5.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="296" id="S5.F3.sf1.g1" src="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/x3.png" width="402">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S5.F3.sf1.3.2" style="font-size:90%;">HumanEval</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="296" id="S5.F3.sf2.g1" src="./AST-T5_ Structure-Aware Pretraining for Code Generation and Understanding_files/x4.png" width="402">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S5.F3.sf2.3.2" style="font-size:90%;">MBPP</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.5.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S5.F3.6.2" style="font-size:90%;">Visualizations of <span class="ltx_ERROR undefined" id="S5.F3.6.2.1">\nolbreaks</span>AST-T5’s performance on HumanEval and MBPP compared to other models compared to models exceeding 300M parameters. Each point on each scatter plot represents a model. The x-axis shows the parameter count in log-scale, while the y-axis shows the Pass@1 rate on HumanEval or MBPP in log-scale. Model open-source status is color-coded: <span class="ltx_text ltx_font_bold" id="S5.F3.6.2.2" style="color:#0000FF;">blue</span> for open-source and <span class="ltx_text ltx_font_bold" id="S5.F3.6.2.3" style="color:#FF0000;">red</span> for proprietary.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.T3" title="In 5.2 Main Results ‣ 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a> shows <span class="ltx_ERROR undefined" id="S5.SS2.p1.1.1">\nolbreaks</span>AST-T5’s performance on downstream tasks compared with previously published results of similarly sized models, specifically those within the “Base” scale (100M to 300M parameters). <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.F3.sf1" title="In Figure 3 ‣ 5.2 Main Results ‣ 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3(a)</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.F3.sf2" title="In Figure 3 ‣ 5.2 Main Results ‣ 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3(b)</span></a> extends this comparison, comparing <span class="ltx_ERROR undefined" id="S5.SS2.p1.1.2">\nolbreaks</span>AST-T5 with larger models using the HumanEval benchmark and the MBPP benchmark, respectively. Additional results on EvalPlus are shown in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.SS4" title="A.4 Evaluation Results on EvalPlus ‣ Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">A.4</span></a>. These results show that:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">
<span class="ltx_ERROR undefined" id="S5.SS2.SSS0.Px1.1.1">\nolbreaks</span>AST-T5 excels as a unified and parameter-efficient LM for various code-related tasks.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">While comparable in size, <span class="ltx_ERROR undefined" id="S5.SS2.SSS0.Px1.p1.1.1">\nolbreaks</span>AST-T5 consistently outperforms similar-sized models such as CodeT5&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib43" title="">2021</a>)</cite> and CodeT5+&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib44" title="">2023</a>)</cite> in code generation, transpilation, and understanding. Notably, while CodeT5 and CodeT5+ are models at the Base scale, they were evaluated across different tasks. Our model, <span class="ltx_ERROR undefined" id="S5.SS2.SSS0.Px1.p1.1.2">\nolbreaks</span>AST-T5, outperforms the best results of these two models across multiple benchmarks at the same time. Moreover, <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.F3.sf1" title="In Figure 3 ‣ 5.2 Main Results ‣ 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3(a)</span></a> highlights <span class="ltx_ERROR undefined" id="S5.SS2.SSS0.Px1.p1.1.3">\nolbreaks</span>AST-T5’s competitiveness against significantly larger models like GPT-J&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang &amp; Komatsuzaki, <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib42" title="">2021</a>)</cite> and LLaMa-7B&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib40" title="">2023</a>)</cite> on the HumanEval benchmark, underscoring our model’s parameter efficiency. Similarly, <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.F3.sf2" title="In Figure 3 ‣ 5.2 Main Results ‣ 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3(b)</span></a> demonstrates <span class="ltx_ERROR undefined" id="S5.SS2.SSS0.Px1.p1.1.4">\nolbreaks</span>AST-T5’s advantages over LLaMa-7B and Codex-2.5B&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib10" title="">2021a</a>)</cite> on the MBPP benchmark, showing the effectiveness of <span class="ltx_ERROR undefined" id="S5.SS2.SSS0.Px1.p1.1.5">\nolbreaks</span>AST-T5.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">
<span class="ltx_ERROR undefined" id="S5.SS2.SSS0.Px2.1.1">\nolbreaks</span>AST-T5 exhibits unique strengths in transpilation through AST-awareness.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S5.T3" title="In 5.2 Main Results ‣ 5 Evaluation Results ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a> highlights <span class="ltx_ERROR undefined" id="S5.SS2.SSS0.Px2.p1.1.1">\nolbreaks</span>AST-T5’s superior performance in code-to-code transpilation tasks, showcasing gains a substantial gain of 2 to 5 points on Bugs2Fix and Java-C# transpilation. In transpilation, while surface-level code can exhibit significant variability, the intrinsic AST structures of the source and target often maintain a notable similarity. The capability of <span class="ltx_ERROR undefined" id="S5.SS2.SSS0.Px2.p1.1.2">\nolbreaks</span>AST-T5 to exploit this structural similarity is crucial to its effectiveness. The benefits of being structure-aware are further exemplified by <span class="ltx_ERROR undefined" id="S5.SS2.SSS0.Px2.p1.1.3">\nolbreaks</span>AST-T5’s leading results in Clone Detection, where it surpasses CodeT5 by 3 points, because AST comparisons yield more precise insights than direct code comparisons.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion and Future Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this work, we present <span class="ltx_ERROR undefined" id="S6.p1.1.1">\nolbreaks</span>AST-T5, a novel pretraining paradigm that harnesses the power of Abstract Syntax Trees (ASTs) to boost the performance of code-centric language models. Using two structure-aware techniques, <span class="ltx_ERROR undefined" id="S6.p1.1.2">\nolbreaks</span>AST-T5 not only outperforms models of comparable size but also competes favorably against some larger counterparts. The simplicity of <span class="ltx_ERROR undefined" id="S6.p1.1.3">\nolbreaks</span>AST-T5 lies in its singular pretraining objective and its adaptability as a drop-in replacement for any encoder-decoder LM, highlighting its potential for real-world deployments. Moving forward, we aim to explore the scalability of <span class="ltx_ERROR undefined" id="S6.p1.1.4">\nolbreaks</span>AST-T5 by training larger models on more expansive datasets.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">We thank the reviewers and metareviewers at ICML for their constructive feedback and support. This work is supported in part by gift from Meta, the U.S. National Science Foundation through grants IIS-1955488, IIS-2027575, ARO W911NF2110339, ONR N00014-21-1-2724, and DOE awards DE-SC0016260, DE-SC0021982. The AI training platform and computation resources supporting this work were provided by High-Flyer AI Fundamental Research Co. Ltd, Hangzhou, China. We thank Sida Wang, Chris Cummins, Volker Seeker, and Hugh Leather for their valuable discussions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Impact Statement</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">In this paper, we introduce <span class="ltx_ERROR undefined" id="Sx2.p1.1.1">\nolbreaks</span>AST-T5, a language model aimed at automated generation, transpilation, and understanding of code. The advancement of LLMs in code generation raises concerns about automated code production’s security, privacy, and potential misuse. There is a risk that improved code generation capabilities could be exploited for malicious purposes, such as automating the creation of software vulnerabilities or facilitating the development of harmful software. Our research emphasizes the importance of responsible AI development and use, advocating for continuous monitoring, ethical guidelines, and safeguards to mitigate these risks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmad et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ahmad, W.&nbsp;U., Chakraborty, S., Ray, B., and Chang, K.-W.

</span>
<span class="ltx_bibblock">Unified pre-training for program understanding and generation.

</span>
<span class="ltx_bibblock">Apr 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2103.06333</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2103.06333" title="">http://arxiv.org/abs/2103.06333</a>.

</span>
<span class="ltx_bibblock">arXiv:2103.06333 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Allamanis et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Allamanis, M., Brockschmidt, M., and Khademi, M.

</span>
<span class="ltx_bibblock">Learning to represent programs with graphs.

</span>
<span class="ltx_bibblock">Nov 2017.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/1711.00740" title="">https://arxiv.org/abs/1711.00740</a>.

</span>
<span class="ltx_bibblock">arXiv:1711.00740 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alon et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alon, U., Sadaka, R., Levy, O., and Yahav, E.

</span>
<span class="ltx_bibblock">Structural language models of code.

</span>
<span class="ltx_bibblock">July 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.1910.00577</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1910.00577" title="">http://arxiv.org/abs/1910.00577</a>.

</span>
<span class="ltx_bibblock">arXiv:1910.00577 [cs, stat].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Athiwaratkun et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Athiwaratkun, B., Gouda, S.&nbsp;K., Wang, Z., Li, X., Tian, Y., Tan, M., Ahmad, W.&nbsp;U., Wang, S., Sun, Q., Shang, M., Gonugondla, S.&nbsp;K., Ding, H., Kumar, V., Fulton, N., Farahani, A., Jain, S., Giaquinto, R., Qian, H., Ramanathan, M.&nbsp;K., Nallapati, R., Ray, B., Bhatia, P., Sengupta, S., Roth, D., and Xiang, B.

</span>
<span class="ltx_bibblock">Multi-lingual evaluation of code generation models.

</span>
<span class="ltx_bibblock">(arXiv:2210.14868), March 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2210.14868" title="">http://arxiv.org/abs/2210.14868</a>.

</span>
<span class="ltx_bibblock">arXiv:2210.14868 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Austin et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., and Sutton, C.

</span>
<span class="ltx_bibblock">Program synthesis with large language models.

</span>
<span class="ltx_bibblock">Aug 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2108.07732</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2108.07732" title="">http://arxiv.org/abs/2108.07732</a>.

</span>
<span class="ltx_bibblock">arXiv:2108.07732 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bach et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bach, S.&nbsp;H., Sanh, V., Yong, Z.-X., Webson, A., Raffel, C., Nayak, N.&nbsp;V., Sharma, A., Kim, T., Bari, M.&nbsp;S., Fevry, T., Alyafeai, Z., Dey, M., Santilli, A., Sun, Z., Ben-David, S., Xu, C., Chhablani, G., Wang, H., Fries, J.&nbsp;A., Al-shaibani, M.&nbsp;S., Sharma, S., Thakker, U., Almubarak, K., Tang, X., Radev, D., Jiang, M. T.-J., and Rush, A.&nbsp;M.

</span>
<span class="ltx_bibblock">PromptSource: An integrated development environment and repository for natural language prompts.

</span>
<span class="ltx_bibblock">March 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2202.01279</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2202.01279" title="">http://arxiv.org/abs/2202.01279</a>.

</span>
<span class="ltx_bibblock">arXiv:2202.01279 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">BigScience (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
BigScience.

</span>
<span class="ltx_bibblock">Bigscience Language Open-science Open-access Multilingual (BLOOM), May 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/bigscience/bloom" title="">https://huggingface.co/bigscience/bloom</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Black et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Black, S., Gao, L., Wang, P., Leahy, C., and Biderman, S.

</span>
<span class="ltx_bibblock">GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow, March 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.5281/zenodo.5297715" title="">https://doi.org/10.5281/zenodo.5297715</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Brown, T.&nbsp;B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.&nbsp;M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">Jul 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2005.14165</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2005.14165" title="">http://arxiv.org/abs/2005.14165</a>.

</span>
<span class="ltx_bibblock">arXiv:2005.14165 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2021a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d.&nbsp;O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P., Such, F.&nbsp;P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss, A., Guss, W.&nbsp;H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr, A.&nbsp;N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., and Zaremba, W.

</span>
<span class="ltx_bibblock">Evaluating large language models trained on code.

</span>
<span class="ltx_bibblock">Jul 2021a.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2107.03374</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2107.03374" title="">http://arxiv.org/abs/2107.03374</a>.

</span>
<span class="ltx_bibblock">arXiv:2107.03374 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chen, X., Liu, C., and Song, D.

</span>
<span class="ltx_bibblock">Execution-guided neural program synthesis.

</span>
<span class="ltx_bibblock">Sep 2018.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=H1gfOiAqYm" title="">https://openreview.net/forum?id=H1gfOiAqYm</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2021b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chen, X., Song, D., and Tian, Y.

</span>
<span class="ltx_bibblock">Latent execution for neural program synthesis.

</span>
<span class="ltx_bibblock">Jun 2021b.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2107.00101" title="">https://arxiv.org/abs/2107.00101</a>.

</span>
<span class="ltx_bibblock">arXiv:2107.00101 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H.&nbsp;W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Prabhakaran, V., Reif, E., Du, N., Hutchinson, B., Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari, G., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev, S., Michalewski, H., Garcia, X., Misra, V., Robinson, K., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim, H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D., Agrawal, S., Omernick, M., Dai, A.&nbsp;M., Pillai, T.&nbsp;S., Pellat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov, O., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M., Firat, O., Catasta, M., Wei, J., Meier-Hellstern, K., Eck, D., Dean, J., Petrov, S., and Fiedel, N.

</span>
<span class="ltx_bibblock">PaLM: Scaling language modeling with pathways.

</span>
<span class="ltx_bibblock">Oct 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2204.02311</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2204.02311" title="">http://arxiv.org/abs/2204.02311</a>.

</span>
<span class="ltx_bibblock">arXiv:2204.02311 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dao et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dao, T., Fu, D.&nbsp;Y., Ermon, S., Rudra, A., and Ré, C.

</span>
<span class="ltx_bibblock">FlashAttention: Fast and memory-efficient exact attention with IO-awareness.

</span>
<span class="ltx_bibblock">June 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2205.14135</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2205.14135" title="">http://arxiv.org/abs/2205.14135</a>.

</span>
<span class="ltx_bibblock">arXiv:2205.14135 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., and Zhou, M.

</span>
<span class="ltx_bibblock">CodeBERT: A pre-trained model for programming and natural languages.

</span>
<span class="ltx_bibblock">Sep 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2002.08155</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2002.08155" title="">http://arxiv.org/abs/2002.08155</a>.

</span>
<span class="ltx_bibblock">arXiv:2002.08155 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fried et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fried, D., Aghajanyan, A., Lin, J., Wang, S., Wallace, E., Shi, F., Zhong, R., Yih, W.-t., Zettlemoyer, L., and Lewis, M.

</span>
<span class="ltx_bibblock">InCoder: A generative model for code infilling and synthesis.

</span>
<span class="ltx_bibblock">Apr 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2204.05999</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2204.05999" title="">http://arxiv.org/abs/2204.05999</a>.

</span>
<span class="ltx_bibblock">arXiv:2204.05999 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Guo, D., Ren, S., Lu, S., Feng, Z., Tang, D., Liu, S., Zhou, L., Duan, N., Svyatkovskiy, A., Fu, S., Tufano, M., Deng, S.&nbsp;K., Clement, C., Drain, D., Sundaresan, N., Yin, J., Jiang, D., and Zhou, M.

</span>
<span class="ltx_bibblock">GraphCodeBERT: Pre-training code representations with data flow.

</span>
<span class="ltx_bibblock">Sep 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2009.08366</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2009.08366" title="">http://arxiv.org/abs/2009.08366</a>.

</span>
<span class="ltx_bibblock">arXiv:2009.08366 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Husain et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Husain, H., Wu, H.-H., Gazit, T., Allamanis, M., and Brockschmidt, M.

</span>
<span class="ltx_bibblock">CodeSearchNet challenge: Evaluating the state of semantic code search.

</span>
<span class="ltx_bibblock">Jun 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.1909.09436</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1909.09436" title="">http://arxiv.org/abs/1909.09436</a>.

</span>
<span class="ltx_bibblock">arXiv:1909.09436 [cs, stat].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iyer et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Iyer, S., Konstas, I., Cheung, A., and Zettlemoyer, L.

</span>
<span class="ltx_bibblock">Mapping language to code in programmatic context.

</span>
<span class="ltx_bibblock">Aug 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.1808.09588</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1808.09588" title="">http://arxiv.org/abs/1808.09588</a>.

</span>
<span class="ltx_bibblock">arXiv:1808.09588 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kim, S., Zhao, J., Tian, Y., and Chandra, S.

</span>
<span class="ltx_bibblock">Code prediction by feeding trees to transformers.

</span>
<span class="ltx_bibblock">March 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2003.13848</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2003.13848" title="">http://arxiv.org/abs/2003.13848</a>.

</span>
<span class="ltx_bibblock">arXiv:2003.13848 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocetkov et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kocetkov, D., Li, R., Allal, L.&nbsp;B., Li, J., Mou, C., Ferrandis, C.&nbsp;M., Jernite, Y., Mitchell, M., Hughes, S., Wolf, T., Bahdanau, D., von Werra, L., and de&nbsp;Vries, H.

</span>
<span class="ltx_bibblock">The Stack: 3 TB of permissively licensed source code.

</span>
<span class="ltx_bibblock">(arXiv:2211.15533), November 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2211.15533</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2211.15533" title="">http://arxiv.org/abs/2211.15533</a>.

</span>
<span class="ltx_bibblock">arXiv:2211.15533 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lachaux et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lachaux, M.-A., Roziere, B., Chanussot, L., and Lample, G.

</span>
<span class="ltx_bibblock">Unsupervised translation of programming languages.

</span>
<span class="ltx_bibblock">Sep 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2006.03511</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2006.03511" title="">http://arxiv.org/abs/2006.03511</a>.

</span>
<span class="ltx_bibblock">arXiv:2006.03511 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L.

</span>
<span class="ltx_bibblock">BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.

</span>
<span class="ltx_bibblock">Oct 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.1910.13461</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1910.13461" title="">http://arxiv.org/abs/1910.13461</a>.

</span>
<span class="ltx_bibblock">arXiv:1910.13461 [cs, stat].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Li, J., Wang, Y., Lyu, M.&nbsp;R., and King, I.

</span>
<span class="ltx_bibblock">Code completion with neural attention and pointer networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence</em>, pp.&nbsp; 4159–4165, July 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.24963/ijcai.2018/578</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1711.09573" title="">http://arxiv.org/abs/1711.09573</a>.

</span>
<span class="ltx_bibblock">arXiv:1711.09573 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Liu, J., Xia, C.&nbsp;S., Wang, Y., and Zhang, L.

</span>
<span class="ltx_bibblock">Is your code generated by chatGPT really correct? rigorous evaluation of large language models for code generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Thirty-seventh Conference on Neural Information Processing Systems</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=1qvx610Cu7" title="">https://openreview.net/forum?id=1qvx610Cu7</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V.

</span>
<span class="ltx_bibblock">RoBERTa: A robustly optimized BERT pretraining approach.

</span>
<span class="ltx_bibblock">Jul 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.1907.11692</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1907.11692" title="">http://arxiv.org/abs/1907.11692</a>.

</span>
<span class="ltx_bibblock">arXiv:1907.11692 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lu, S., Guo, D., Ren, S., Huang, J., Svyatkovskiy, A., Blanco, A., Clement, C., Drain, D., Jiang, D., Tang, D., Li, G., Zhou, L., Shou, L., Zhou, L., Tufano, M., Gong, M., Zhou, M., Duan, N., Sundaresan, N., Deng, S.&nbsp;K., Fu, S., and Liu, S.

</span>
<span class="ltx_bibblock">CodeXGLUE: A machine learning benchmark dataset for code understanding and generation.

</span>
<span class="ltx_bibblock">Mar 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2102.04664</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2102.04664" title="">http://arxiv.org/abs/2102.04664</a>.

</span>
<span class="ltx_bibblock">arXiv:2102.04664 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nijkamp et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nijkamp, E., Hayashi, H., Xiong, C., Savarese, S., and Zhou, Y.

</span>
<span class="ltx_bibblock">CodeGen2: Lessons for training LLMs on programming and natural languages.

</span>
<span class="ltx_bibblock">(arXiv:2305.02309), July 2023a.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2305.02309</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2305.02309" title="">http://arxiv.org/abs/2305.02309</a>.

</span>
<span class="ltx_bibblock">arXiv:2305.02309 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nijkamp et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nijkamp, E., Pang, B., Hayashi, H., Tu, L., Wang, H., Zhou, Y., Savarese, S., and Xiong, C.

</span>
<span class="ltx_bibblock">CodeGen: An open large language model for code with multi-turn program synthesis.

</span>
<span class="ltx_bibblock">Feb 2023b.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2203.13474</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2203.13474" title="">http://arxiv.org/abs/2203.13474</a>.

</span>
<span class="ltx_bibblock">arXiv:2203.13474 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.&nbsp;L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., and Lowe, R.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock">Mar 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2203.02155</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2203.02155" title="">http://arxiv.org/abs/2203.02155</a>.

</span>
<span class="ltx_bibblock">arXiv:2203.02155 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rabinovich et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rabinovich, M., Stern, M., and Klein, D.

</span>
<span class="ltx_bibblock">Abstract syntax networks for code generation and semantic parsing.

</span>
<span class="ltx_bibblock">April 2017.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.1704.07535</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1704.07535" title="">http://arxiv.org/abs/1704.07535</a>.

</span>
<span class="ltx_bibblock">arXiv:1704.07535 [cs, stat].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P.&nbsp;J.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock">Jul 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.1910.10683</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1910.10683" title="">http://arxiv.org/abs/1910.10683</a>.

</span>
<span class="ltx_bibblock">arXiv:1910.10683 [cs, stat].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ren, S., Guo, D., Lu, S., Zhou, L., Liu, S., Tang, D., Sundaresan, N., Zhou, M., Blanco, A., and Ma, S.

</span>
<span class="ltx_bibblock">CodeBLEU: a method for automatic evaluation of code synthesis.

</span>
<span class="ltx_bibblock">(arXiv:2009.10297), September 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2009.10297</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2009.10297" title="">http://arxiv.org/abs/2009.10297</a>.

</span>
<span class="ltx_bibblock">arXiv:2009.10297 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roziere et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Roziere, B., Lachaux, M.-A., Szafraniec, M., and Lample, G.

</span>
<span class="ltx_bibblock">DOBF: A deobfuscation pre-training objective for programming languages.

</span>
<span class="ltx_bibblock">Oct 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2102.07492</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2102.07492" title="">http://arxiv.org/abs/2102.07492</a>.

</span>
<span class="ltx_bibblock">arXiv:2102.07492 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rozière et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rozière, B., Gehring, J., Gloeckle, F., Sootla, S., Gat, I., Tan, X.&nbsp;E., Adi, Y., Liu, J., Remez, T., Rapin, J., Kozhevnikov, A., Evtimov, I., Bitton, J., Bhatt, M., Ferrer, C.&nbsp;C., Grattafiori, A., Xiong, W., Défossez, A., Copet, J., Azhar, F., Touvron, H., Martin, L., Usunier, N., Scialom, T., and Synnaeve, G.

</span>
<span class="ltx_bibblock">Code llama: Open foundation models for code.

</span>
<span class="ltx_bibblock">Aug 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2308.12950</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2308.12950" title="">http://arxiv.org/abs/2308.12950</a>.

</span>
<span class="ltx_bibblock">arXiv:2308.12950 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sanh, V., Webson, A., Raffel, C., Bach, S.&nbsp;H., Sutawika, L., Alyafeai, Z., Chaffin, A., Stiegler, A., Scao, T.&nbsp;L., Raja, A., Dey, M., Bari, M.&nbsp;S., Xu, C., Thakker, U., Sharma, S.&nbsp;S., Szczechla, E., Kim, T., Chhablani, G., Nayak, N., Datta, D., Chang, J., Jiang, M. T.-J., Wang, H., Manica, M., Shen, S., Yong, Z.&nbsp;X., Pandey, H., Bawden, R., Wang, T., Neeraj, T., Rozen, J., Sharma, A., Santilli, A., Fevry, T., Fries, J.&nbsp;A., Teehan, R., Bers, T., Biderman, S., Gao, L., Wolf, T., and Rush, A.&nbsp;M.

</span>
<span class="ltx_bibblock">Multitask prompted training enables zero-shot task generalization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv.org</em>, Oct 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2110.08207v3" title="">https://arxiv.org/abs/2110.08207v3</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shojaee et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shojaee, P., Jain, A., Tipirneni, S., and Reddy, C.&nbsp;K.

</span>
<span class="ltx_bibblock">Execution-based code generation using deep reinforcement learning.

</span>
<span class="ltx_bibblock">Jan 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2301.13816" title="">https://arxiv.org/abs/2301.13816</a>.

</span>
<span class="ltx_bibblock">arXiv:2301.13816 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Svajlenko et&nbsp;al. (2014)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Svajlenko, J., Islam, J.&nbsp;F., Keivanloo, I., Roy, C.&nbsp;K., and Mia, M.&nbsp;M.

</span>
<span class="ltx_bibblock">Towards a big data curated benchmark of inter-project code clones.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">2014 IEEE International Conference on Software Maintenance and Evolution</em>, pp.&nbsp; 476–480, Sep 2014.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICSME.2014.77</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tipirneni et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tipirneni, S., Zhu, M., and Reddy, C.&nbsp;K.

</span>
<span class="ltx_bibblock">StructCoder: Structure-aware transformer for code generation.

</span>
<span class="ltx_bibblock">May 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2206.05239</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2206.05239" title="">http://arxiv.org/abs/2206.05239</a>.

</span>
<span class="ltx_bibblock">arXiv:2206.05239 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lample, G.

</span>
<span class="ltx_bibblock">LLaMA: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock">Feb 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2302.13971</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2302.13971" title="">http://arxiv.org/abs/2302.13971</a>.

</span>
<span class="ltx_bibblock">arXiv:2302.13971 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tufano et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tufano, M., Watson, C., Bavota, G., Di&nbsp;Penta, M., White, M., and Poshyvanyk, D.

</span>
<span class="ltx_bibblock">An empirical study on learning bug-fixing patches in the wild via neural machine translation.

</span>
<span class="ltx_bibblock">May 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.1812.08693</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1812.08693" title="">http://arxiv.org/abs/1812.08693</a>.

</span>
<span class="ltx_bibblock">arXiv:1812.08693 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang &amp; Komatsuzaki (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wang, B. and Komatsuzaki, A.

</span>
<span class="ltx_bibblock">GPT-J-6B: 6B JAX-based Transformer, Jun 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/" title="">https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wang, Y., Wang, W., Joty, S., and Hoi, S. C.&nbsp;H.

</span>
<span class="ltx_bibblock">CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation.

</span>
<span class="ltx_bibblock">Sep 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2109.00859</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2109.00859" title="">http://arxiv.org/abs/2109.00859</a>.

</span>
<span class="ltx_bibblock">arXiv:2109.00859 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wang, Y., Le, H., Gotmare, A.&nbsp;D., Bui, N. D.&nbsp;Q., Li, J., and Hoi, S. C.&nbsp;H.

</span>
<span class="ltx_bibblock">CodeT5+: Open code large language models for code understanding and generation.

</span>
<span class="ltx_bibblock">May 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2305.07922</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2305.07922" title="">http://arxiv.org/abs/2305.07922</a>.

</span>
<span class="ltx_bibblock">arXiv:2305.07922 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M., Chen, S., Dewan, C., Diab, M., Li, X., Lin, X.&nbsp;V., Mihaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D., Koura, P.&nbsp;S., Sridhar, A., Wang, T., and Zettlemoyer, L.

</span>
<span class="ltx_bibblock">OPT: Open pre-trained transformer language models.

</span>
<span class="ltx_bibblock">(arXiv:2205.01068), June 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2205.01068</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2205.01068" title="">http://arxiv.org/abs/2205.01068</a>.

</span>
<span class="ltx_bibblock">arXiv:2205.01068 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhou, Y., Liu, S., Siow, J., Du, X., and Liu, Y.

</span>
<span class="ltx_bibblock">Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks.

</span>
<span class="ltx_bibblock">Sep 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.1909.03496</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1909.03496" title="">http://arxiv.org/abs/1909.03496</a>.

</span>
<span class="ltx_bibblock">arXiv:1909.03496 [cs, stat].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zügner et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zügner, D., Kirschstein, T., Catasta, M., Leskovec, J., and Günnemann, S.

</span>
<span class="ltx_bibblock">Language-agnostic representation learning of source code from structure and context.

</span>
<span class="ltx_bibblock">March 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2103.11318</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2103.11318" title="">http://arxiv.org/abs/2103.11318</a>.

</span>
<span class="ltx_bibblock">arXiv:2103.11318 [cs].

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Limitations</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS1.p1">
<span class="ltx_ERROR undefined" id="A1.SS1.p1.1">\nolbreaks</span>
<p class="ltx_p" id="A1.SS1.p1.2">AST-T5 is specifically designed to enhance code generation performance by exclusively masking code within AST subtrees during pretraining. While this specialized approach is advantageous for code generation tasks, it may result in suboptimal performance in natural language generation. Acknowledging this limitation, future versions of <span class="ltx_ERROR undefined" id="A1.SS1.p1.2.1">\nolbreaks</span>AST-T5 could investigate strategies such as masking docstrings and comments to broaden its applicability. This would potentially improve performance across various tasks, including code summarization.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>More about AST-Aware Segmentation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">In <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#S3.SS2" title="3.2 AST-Aware Segmentation ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2</span></a>, we use a dynamic programming algorithm to calculate the segmentation that results in the least number of AST structure breaks. A naive implementation of the DP algorithm is shown in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#alg3" title="In A.2 More about AST-Aware Segmentation ‣ Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Algorithm</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg3.2.1.1">Algorithm 3</span> </span> Dynamic Programming in AST-Aware Segmentation (Before Optimization)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_figure_panel undefined" id="alg3.3">{minted}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="alg3.4">[linenos,xleftmargin=20pt]python
for k in range(1, m + 1):
for i in range(1, n + 1):
best_j = i - max_len
for j in range(i - max_len + 1, i):
if dp[k - 1, j] ¡ dp[k - 1, best_j]:
best_j = j
prev[k, i] = best_j
dp[k, i] = cost[i] + min_value</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS2.p2">
<p class="ltx_p" id="A1.SS2.p2.4">Denote the length of the code file (in tokens) by <math alttext="n" class="ltx_Math" display="inline" id="A1.SS2.p2.1.m1.1"><semantics id="A1.SS2.p2.1.m1.1a"><mi id="A1.SS2.p2.1.m1.1.1" xref="A1.SS2.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.1.m1.1b"><ci id="A1.SS2.p2.1.m1.1.1.cmml" xref="A1.SS2.p2.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p2.1.m1.1d">italic_n</annotation></semantics></math>. In the algorithm, <math alttext="m" class="ltx_Math" display="inline" id="A1.SS2.p2.2.m2.1"><semantics id="A1.SS2.p2.2.m2.1a"><mi id="A1.SS2.p2.2.m2.1.1" xref="A1.SS2.p2.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.2.m2.1b"><ci id="A1.SS2.p2.2.m2.1.1.cmml" xref="A1.SS2.p2.2.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.2.m2.1c">m</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p2.2.m2.1d">italic_m</annotation></semantics></math> denotes the maximum number of chunks that the file can be split into, which is approximately <math alttext="n/\mathrm{max\_len}" class="ltx_Math" display="inline" id="A1.SS2.p2.3.m3.1"><semantics id="A1.SS2.p2.3.m3.1a"><mrow id="A1.SS2.p2.3.m3.1.1" xref="A1.SS2.p2.3.m3.1.1.cmml"><mrow id="A1.SS2.p2.3.m3.1.1.2" xref="A1.SS2.p2.3.m3.1.1.2.cmml"><mi id="A1.SS2.p2.3.m3.1.1.2.2" xref="A1.SS2.p2.3.m3.1.1.2.2.cmml">n</mi><mo id="A1.SS2.p2.3.m3.1.1.2.1" xref="A1.SS2.p2.3.m3.1.1.2.1.cmml">/</mo><mi id="A1.SS2.p2.3.m3.1.1.2.3" xref="A1.SS2.p2.3.m3.1.1.2.3.cmml">max</mi></mrow><mo id="A1.SS2.p2.3.m3.1.1.1" xref="A1.SS2.p2.3.m3.1.1.1.cmml">⁢</mo><mi id="A1.SS2.p2.3.m3.1.1.3" mathvariant="normal" xref="A1.SS2.p2.3.m3.1.1.3.cmml">_</mi><mo id="A1.SS2.p2.3.m3.1.1.1a" xref="A1.SS2.p2.3.m3.1.1.1.cmml">⁢</mo><mi id="A1.SS2.p2.3.m3.1.1.4" xref="A1.SS2.p2.3.m3.1.1.4.cmml">len</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.3.m3.1b"><apply id="A1.SS2.p2.3.m3.1.1.cmml" xref="A1.SS2.p2.3.m3.1.1"><times id="A1.SS2.p2.3.m3.1.1.1.cmml" xref="A1.SS2.p2.3.m3.1.1.1"></times><apply id="A1.SS2.p2.3.m3.1.1.2.cmml" xref="A1.SS2.p2.3.m3.1.1.2"><divide id="A1.SS2.p2.3.m3.1.1.2.1.cmml" xref="A1.SS2.p2.3.m3.1.1.2.1"></divide><ci id="A1.SS2.p2.3.m3.1.1.2.2.cmml" xref="A1.SS2.p2.3.m3.1.1.2.2">𝑛</ci><ci id="A1.SS2.p2.3.m3.1.1.2.3.cmml" xref="A1.SS2.p2.3.m3.1.1.2.3">max</ci></apply><ci id="A1.SS2.p2.3.m3.1.1.3.cmml" xref="A1.SS2.p2.3.m3.1.1.3">_</ci><ci id="A1.SS2.p2.3.m3.1.1.4.cmml" xref="A1.SS2.p2.3.m3.1.1.4">len</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.3.m3.1c">n/\mathrm{max\_len}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p2.3.m3.1d">italic_n / roman_max _ roman_len</annotation></semantics></math>. So this implementation has time complexity <math alttext="O(mn\cdot\mathrm{max\_len})=O(n^{2})" class="ltx_Math" display="inline" id="A1.SS2.p2.4.m4.2"><semantics id="A1.SS2.p2.4.m4.2a"><mrow id="A1.SS2.p2.4.m4.2.2" xref="A1.SS2.p2.4.m4.2.2.cmml"><mrow id="A1.SS2.p2.4.m4.1.1.1" xref="A1.SS2.p2.4.m4.1.1.1.cmml"><mi id="A1.SS2.p2.4.m4.1.1.1.3" xref="A1.SS2.p2.4.m4.1.1.1.3.cmml">O</mi><mo id="A1.SS2.p2.4.m4.1.1.1.2" xref="A1.SS2.p2.4.m4.1.1.1.2.cmml">⁢</mo><mrow id="A1.SS2.p2.4.m4.1.1.1.1.1" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.cmml"><mo id="A1.SS2.p2.4.m4.1.1.1.1.1.2" stretchy="false" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.cmml">(</mo><mrow id="A1.SS2.p2.4.m4.1.1.1.1.1.1" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.cmml"><mrow id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.cmml"><mrow id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.cmml"><mi id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.2" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.2.cmml">m</mi><mo id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.1" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.1.cmml">⁢</mo><mi id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.3" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.3.cmml">n</mi></mrow><mo id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.1.cmml">⋅</mo><mi id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.3" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.3.cmml">max</mi></mrow><mo id="A1.SS2.p2.4.m4.1.1.1.1.1.1.1" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="A1.SS2.p2.4.m4.1.1.1.1.1.1.3" mathvariant="normal" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.3.cmml">_</mi><mo id="A1.SS2.p2.4.m4.1.1.1.1.1.1.1a" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="A1.SS2.p2.4.m4.1.1.1.1.1.1.4" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.4.cmml">len</mi></mrow><mo id="A1.SS2.p2.4.m4.1.1.1.1.1.3" stretchy="false" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.SS2.p2.4.m4.2.2.3" xref="A1.SS2.p2.4.m4.2.2.3.cmml">=</mo><mrow id="A1.SS2.p2.4.m4.2.2.2" xref="A1.SS2.p2.4.m4.2.2.2.cmml"><mi id="A1.SS2.p2.4.m4.2.2.2.3" xref="A1.SS2.p2.4.m4.2.2.2.3.cmml">O</mi><mo id="A1.SS2.p2.4.m4.2.2.2.2" xref="A1.SS2.p2.4.m4.2.2.2.2.cmml">⁢</mo><mrow id="A1.SS2.p2.4.m4.2.2.2.1.1" xref="A1.SS2.p2.4.m4.2.2.2.1.1.1.cmml"><mo id="A1.SS2.p2.4.m4.2.2.2.1.1.2" stretchy="false" xref="A1.SS2.p2.4.m4.2.2.2.1.1.1.cmml">(</mo><msup id="A1.SS2.p2.4.m4.2.2.2.1.1.1" xref="A1.SS2.p2.4.m4.2.2.2.1.1.1.cmml"><mi id="A1.SS2.p2.4.m4.2.2.2.1.1.1.2" xref="A1.SS2.p2.4.m4.2.2.2.1.1.1.2.cmml">n</mi><mn id="A1.SS2.p2.4.m4.2.2.2.1.1.1.3" xref="A1.SS2.p2.4.m4.2.2.2.1.1.1.3.cmml">2</mn></msup><mo id="A1.SS2.p2.4.m4.2.2.2.1.1.3" stretchy="false" xref="A1.SS2.p2.4.m4.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.4.m4.2b"><apply id="A1.SS2.p2.4.m4.2.2.cmml" xref="A1.SS2.p2.4.m4.2.2"><eq id="A1.SS2.p2.4.m4.2.2.3.cmml" xref="A1.SS2.p2.4.m4.2.2.3"></eq><apply id="A1.SS2.p2.4.m4.1.1.1.cmml" xref="A1.SS2.p2.4.m4.1.1.1"><times id="A1.SS2.p2.4.m4.1.1.1.2.cmml" xref="A1.SS2.p2.4.m4.1.1.1.2"></times><ci id="A1.SS2.p2.4.m4.1.1.1.3.cmml" xref="A1.SS2.p2.4.m4.1.1.1.3">𝑂</ci><apply id="A1.SS2.p2.4.m4.1.1.1.1.1.1.cmml" xref="A1.SS2.p2.4.m4.1.1.1.1.1"><times id="A1.SS2.p2.4.m4.1.1.1.1.1.1.1.cmml" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.1"></times><apply id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.cmml" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2"><ci id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.1.cmml" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.1">⋅</ci><apply id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.cmml" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2"><times id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.1.cmml" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.1"></times><ci id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.2.cmml" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.2">𝑚</ci><ci id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.3.cmml" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.2.3">𝑛</ci></apply><ci id="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.3.cmml" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.2.3">max</ci></apply><ci id="A1.SS2.p2.4.m4.1.1.1.1.1.1.3.cmml" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.3">_</ci><ci id="A1.SS2.p2.4.m4.1.1.1.1.1.1.4.cmml" xref="A1.SS2.p2.4.m4.1.1.1.1.1.1.4">len</ci></apply></apply><apply id="A1.SS2.p2.4.m4.2.2.2.cmml" xref="A1.SS2.p2.4.m4.2.2.2"><times id="A1.SS2.p2.4.m4.2.2.2.2.cmml" xref="A1.SS2.p2.4.m4.2.2.2.2"></times><ci id="A1.SS2.p2.4.m4.2.2.2.3.cmml" xref="A1.SS2.p2.4.m4.2.2.2.3">𝑂</ci><apply id="A1.SS2.p2.4.m4.2.2.2.1.1.1.cmml" xref="A1.SS2.p2.4.m4.2.2.2.1.1"><csymbol cd="ambiguous" id="A1.SS2.p2.4.m4.2.2.2.1.1.1.1.cmml" xref="A1.SS2.p2.4.m4.2.2.2.1.1">superscript</csymbol><ci id="A1.SS2.p2.4.m4.2.2.2.1.1.1.2.cmml" xref="A1.SS2.p2.4.m4.2.2.2.1.1.1.2">𝑛</ci><cn id="A1.SS2.p2.4.m4.2.2.2.1.1.1.3.cmml" type="integer" xref="A1.SS2.p2.4.m4.2.2.2.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.4.m4.2c">O(mn\cdot\mathrm{max\_len})=O(n^{2})</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p2.4.m4.2d">italic_O ( italic_m italic_n ⋅ roman_max _ roman_len ) = italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math>, which is not feasible for longer code files. To optimize this algorithm, we use a monotonic queue to compute the sliding-window minimum, as described in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#alg1" title="In 3.2 AST-Aware Segmentation ‣ 3 Method ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Algorithm</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS2.p3">
<p class="ltx_p" id="A1.SS2.p3.3">Each element is only pushed into and popped out of the monotonic queue once, so the time complexity of the optimized algorithm is <math alttext="O(nm)=O(n^{2}/\mathrm{max\_len})" class="ltx_Math" display="inline" id="A1.SS2.p3.1.m1.2"><semantics id="A1.SS2.p3.1.m1.2a"><mrow id="A1.SS2.p3.1.m1.2.2" xref="A1.SS2.p3.1.m1.2.2.cmml"><mrow id="A1.SS2.p3.1.m1.1.1.1" xref="A1.SS2.p3.1.m1.1.1.1.cmml"><mi id="A1.SS2.p3.1.m1.1.1.1.3" xref="A1.SS2.p3.1.m1.1.1.1.3.cmml">O</mi><mo id="A1.SS2.p3.1.m1.1.1.1.2" xref="A1.SS2.p3.1.m1.1.1.1.2.cmml">⁢</mo><mrow id="A1.SS2.p3.1.m1.1.1.1.1.1" xref="A1.SS2.p3.1.m1.1.1.1.1.1.1.cmml"><mo id="A1.SS2.p3.1.m1.1.1.1.1.1.2" stretchy="false" xref="A1.SS2.p3.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="A1.SS2.p3.1.m1.1.1.1.1.1.1" xref="A1.SS2.p3.1.m1.1.1.1.1.1.1.cmml"><mi id="A1.SS2.p3.1.m1.1.1.1.1.1.1.2" xref="A1.SS2.p3.1.m1.1.1.1.1.1.1.2.cmml">n</mi><mo id="A1.SS2.p3.1.m1.1.1.1.1.1.1.1" xref="A1.SS2.p3.1.m1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="A1.SS2.p3.1.m1.1.1.1.1.1.1.3" xref="A1.SS2.p3.1.m1.1.1.1.1.1.1.3.cmml">m</mi></mrow><mo id="A1.SS2.p3.1.m1.1.1.1.1.1.3" stretchy="false" xref="A1.SS2.p3.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.SS2.p3.1.m1.2.2.3" xref="A1.SS2.p3.1.m1.2.2.3.cmml">=</mo><mrow id="A1.SS2.p3.1.m1.2.2.2" xref="A1.SS2.p3.1.m1.2.2.2.cmml"><mi id="A1.SS2.p3.1.m1.2.2.2.3" xref="A1.SS2.p3.1.m1.2.2.2.3.cmml">O</mi><mo id="A1.SS2.p3.1.m1.2.2.2.2" xref="A1.SS2.p3.1.m1.2.2.2.2.cmml">⁢</mo><mrow id="A1.SS2.p3.1.m1.2.2.2.1.1" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.cmml"><mo id="A1.SS2.p3.1.m1.2.2.2.1.1.2" stretchy="false" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="A1.SS2.p3.1.m1.2.2.2.1.1.1" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.cmml"><mrow id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.cmml"><msup id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2.cmml"><mi id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2.2" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2.2.cmml">n</mi><mn id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2.3" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2.3.cmml">2</mn></msup><mo id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.1" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.1.cmml">/</mo><mi id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.3" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.3.cmml">max</mi></mrow><mo id="A1.SS2.p3.1.m1.2.2.2.1.1.1.1" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.1.cmml">⁢</mo><mi id="A1.SS2.p3.1.m1.2.2.2.1.1.1.3" mathvariant="normal" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.3.cmml">_</mi><mo id="A1.SS2.p3.1.m1.2.2.2.1.1.1.1a" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.1.cmml">⁢</mo><mi id="A1.SS2.p3.1.m1.2.2.2.1.1.1.4" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.4.cmml">len</mi></mrow><mo id="A1.SS2.p3.1.m1.2.2.2.1.1.3" stretchy="false" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.1.m1.2b"><apply id="A1.SS2.p3.1.m1.2.2.cmml" xref="A1.SS2.p3.1.m1.2.2"><eq id="A1.SS2.p3.1.m1.2.2.3.cmml" xref="A1.SS2.p3.1.m1.2.2.3"></eq><apply id="A1.SS2.p3.1.m1.1.1.1.cmml" xref="A1.SS2.p3.1.m1.1.1.1"><times id="A1.SS2.p3.1.m1.1.1.1.2.cmml" xref="A1.SS2.p3.1.m1.1.1.1.2"></times><ci id="A1.SS2.p3.1.m1.1.1.1.3.cmml" xref="A1.SS2.p3.1.m1.1.1.1.3">𝑂</ci><apply id="A1.SS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="A1.SS2.p3.1.m1.1.1.1.1.1"><times id="A1.SS2.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="A1.SS2.p3.1.m1.1.1.1.1.1.1.1"></times><ci id="A1.SS2.p3.1.m1.1.1.1.1.1.1.2.cmml" xref="A1.SS2.p3.1.m1.1.1.1.1.1.1.2">𝑛</ci><ci id="A1.SS2.p3.1.m1.1.1.1.1.1.1.3.cmml" xref="A1.SS2.p3.1.m1.1.1.1.1.1.1.3">𝑚</ci></apply></apply><apply id="A1.SS2.p3.1.m1.2.2.2.cmml" xref="A1.SS2.p3.1.m1.2.2.2"><times id="A1.SS2.p3.1.m1.2.2.2.2.cmml" xref="A1.SS2.p3.1.m1.2.2.2.2"></times><ci id="A1.SS2.p3.1.m1.2.2.2.3.cmml" xref="A1.SS2.p3.1.m1.2.2.2.3">𝑂</ci><apply id="A1.SS2.p3.1.m1.2.2.2.1.1.1.cmml" xref="A1.SS2.p3.1.m1.2.2.2.1.1"><times id="A1.SS2.p3.1.m1.2.2.2.1.1.1.1.cmml" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.1"></times><apply id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.cmml" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2"><divide id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.1.cmml" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.1"></divide><apply id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2.cmml" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2.1.cmml" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2">superscript</csymbol><ci id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2.2.cmml" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2.2">𝑛</ci><cn id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2.3.cmml" type="integer" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.2.3">2</cn></apply><ci id="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.3.cmml" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.2.3">max</ci></apply><ci id="A1.SS2.p3.1.m1.2.2.2.1.1.1.3.cmml" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.3">_</ci><ci id="A1.SS2.p3.1.m1.2.2.2.1.1.1.4.cmml" xref="A1.SS2.p3.1.m1.2.2.2.1.1.1.4">len</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.1.m1.2c">O(nm)=O(n^{2}/\mathrm{max\_len})</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p3.1.m1.2d">italic_O ( italic_n italic_m ) = italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / roman_max _ roman_len )</annotation></semantics></math>, making the algorithm <math alttext="\sim" class="ltx_Math" display="inline" id="A1.SS2.p3.2.m2.1"><semantics id="A1.SS2.p3.2.m2.1a"><mo id="A1.SS2.p3.2.m2.1.1" xref="A1.SS2.p3.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.2.m2.1b"><csymbol cd="latexml" id="A1.SS2.p3.2.m2.1.1.cmml" xref="A1.SS2.p3.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.2.m2.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p3.2.m2.1d">∼</annotation></semantics></math> 1000x faster when <math alttext="\mathrm{max\_len}=1024" class="ltx_Math" display="inline" id="A1.SS2.p3.3.m3.1"><semantics id="A1.SS2.p3.3.m3.1a"><mrow id="A1.SS2.p3.3.m3.1.1" xref="A1.SS2.p3.3.m3.1.1.cmml"><mrow id="A1.SS2.p3.3.m3.1.1.2" xref="A1.SS2.p3.3.m3.1.1.2.cmml"><mi id="A1.SS2.p3.3.m3.1.1.2.2" xref="A1.SS2.p3.3.m3.1.1.2.2.cmml">max</mi><mo id="A1.SS2.p3.3.m3.1.1.2.1" xref="A1.SS2.p3.3.m3.1.1.2.1.cmml">⁢</mo><mi id="A1.SS2.p3.3.m3.1.1.2.3" mathvariant="normal" xref="A1.SS2.p3.3.m3.1.1.2.3.cmml">_</mi><mo id="A1.SS2.p3.3.m3.1.1.2.1a" xref="A1.SS2.p3.3.m3.1.1.2.1.cmml">⁢</mo><mi id="A1.SS2.p3.3.m3.1.1.2.4" xref="A1.SS2.p3.3.m3.1.1.2.4.cmml">len</mi></mrow><mo id="A1.SS2.p3.3.m3.1.1.1" xref="A1.SS2.p3.3.m3.1.1.1.cmml">=</mo><mn id="A1.SS2.p3.3.m3.1.1.3" xref="A1.SS2.p3.3.m3.1.1.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.3.m3.1b"><apply id="A1.SS2.p3.3.m3.1.1.cmml" xref="A1.SS2.p3.3.m3.1.1"><eq id="A1.SS2.p3.3.m3.1.1.1.cmml" xref="A1.SS2.p3.3.m3.1.1.1"></eq><apply id="A1.SS2.p3.3.m3.1.1.2.cmml" xref="A1.SS2.p3.3.m3.1.1.2"><times id="A1.SS2.p3.3.m3.1.1.2.1.cmml" xref="A1.SS2.p3.3.m3.1.1.2.1"></times><ci id="A1.SS2.p3.3.m3.1.1.2.2.cmml" xref="A1.SS2.p3.3.m3.1.1.2.2">max</ci><ci id="A1.SS2.p3.3.m3.1.1.2.3.cmml" xref="A1.SS2.p3.3.m3.1.1.2.3">_</ci><ci id="A1.SS2.p3.3.m3.1.1.2.4.cmml" xref="A1.SS2.p3.3.m3.1.1.2.4">len</ci></apply><cn id="A1.SS2.p3.3.m3.1.1.3.cmml" type="integer" xref="A1.SS2.p3.3.m3.1.1.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.3.m3.1c">\mathrm{max\_len}=1024</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p3.3.m3.1d">roman_max _ roman_len = 1024</annotation></semantics></math>. This allows the algorithm to segment each code file with 100k tokens in milliseconds.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Pretraining Hyperparameters</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.T4" title="In A.3 Pretraining Hyperparameters ‣ Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a> shows the pretraining hyperparameters for our proposed <span class="ltx_ERROR undefined" id="A1.SS3.p1.1.1">\nolbreaks</span>AST-T5 model.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A1.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T4.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T4.5.6.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T4.5.6.1.1">Encoder Layers</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A1.T4.5.6.1.2">12</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.7.2">
<td class="ltx_td ltx_align_left" id="A1.T4.5.7.2.1">Decoder Layers</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.7.2.2">12</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.8.3">
<td class="ltx_td ltx_align_left" id="A1.T4.5.8.3.1">Hidden Dimension</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.8.3.2">768</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.9.4">
<td class="ltx_td ltx_align_left" id="A1.T4.5.9.4.1">Peak Learning Rate</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.9.4.2">2e-4</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.10.5">
<td class="ltx_td ltx_align_left" id="A1.T4.5.10.5.1">Batch Size</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.10.5.2">1,024</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.11.6">
<td class="ltx_td ltx_align_left" id="A1.T4.5.11.6.1">Warm-Up Steps</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.11.6.2">10,000</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.12.7">
<td class="ltx_td ltx_align_left" id="A1.T4.5.12.7.1">Total Steps</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.12.7.2">500,000</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.13.8">
<td class="ltx_td ltx_align_left" id="A1.T4.5.13.8.1">Sequence Length</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.13.8.2">1,024</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.14.9">
<td class="ltx_td ltx_align_left" id="A1.T4.5.14.9.1">Mask Ratio</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.14.9.2">25%</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1">
<td class="ltx_td ltx_align_left" id="A1.T4.1.1.1">Min Subtree Corruption Threshold <math alttext="\theta" class="ltx_Math" display="inline" id="A1.T4.1.1.1.m1.1"><semantics id="A1.T4.1.1.1.m1.1a"><mi id="A1.T4.1.1.1.m1.1.1" xref="A1.T4.1.1.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="A1.T4.1.1.1.m1.1b"><ci id="A1.T4.1.1.1.m1.1.1.cmml" xref="A1.T4.1.1.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.1.1.1.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="A1.T4.1.1.1.m1.1d">italic_θ</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.2">5</td>
</tr>
<tr class="ltx_tr" id="A1.T4.2.2">
<td class="ltx_td ltx_align_left" id="A1.T4.2.2.1">Max Subtree Corruption Threshold <math alttext="\theta" class="ltx_Math" display="inline" id="A1.T4.2.2.1.m1.1"><semantics id="A1.T4.2.2.1.m1.1a"><mi id="A1.T4.2.2.1.m1.1.1" xref="A1.T4.2.2.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="A1.T4.2.2.1.m1.1b"><ci id="A1.T4.2.2.1.m1.1.1.cmml" xref="A1.T4.2.2.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.2.2.1.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="A1.T4.2.2.1.m1.1d">italic_θ</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_right" id="A1.T4.2.2.2">100</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.15.10">
<td class="ltx_td ltx_align_left" id="A1.T4.5.15.10.1">Relative Position Encoding Buckets</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.15.10.2">32</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.16.11">
<td class="ltx_td ltx_align_left" id="A1.T4.5.16.11.1">Relative Position Encoding Max Distance</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.16.11.2">128</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.3">
<td class="ltx_td ltx_align_left" id="A1.T4.3.3.1">Adam <math alttext="\epsilon" class="ltx_Math" display="inline" id="A1.T4.3.3.1.m1.1"><semantics id="A1.T4.3.3.1.m1.1a"><mi id="A1.T4.3.3.1.m1.1.1" xref="A1.T4.3.3.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="A1.T4.3.3.1.m1.1b"><ci id="A1.T4.3.3.1.m1.1.1.cmml" xref="A1.T4.3.3.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.3.3.1.m1.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="A1.T4.3.3.1.m1.1d">italic_ϵ</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.3.2">1e-6</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.5">
<td class="ltx_td ltx_align_left" id="A1.T4.5.5.2">Adam (<math alttext="\beta_{1}" class="ltx_Math" display="inline" id="A1.T4.4.4.1.m1.1"><semantics id="A1.T4.4.4.1.m1.1a"><msub id="A1.T4.4.4.1.m1.1.1" xref="A1.T4.4.4.1.m1.1.1.cmml"><mi id="A1.T4.4.4.1.m1.1.1.2" xref="A1.T4.4.4.1.m1.1.1.2.cmml">β</mi><mn id="A1.T4.4.4.1.m1.1.1.3" xref="A1.T4.4.4.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.T4.4.4.1.m1.1b"><apply id="A1.T4.4.4.1.m1.1.1.cmml" xref="A1.T4.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T4.4.4.1.m1.1.1.1.cmml" xref="A1.T4.4.4.1.m1.1.1">subscript</csymbol><ci id="A1.T4.4.4.1.m1.1.1.2.cmml" xref="A1.T4.4.4.1.m1.1.1.2">𝛽</ci><cn id="A1.T4.4.4.1.m1.1.1.3.cmml" type="integer" xref="A1.T4.4.4.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.4.4.1.m1.1c">\beta_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.T4.4.4.1.m1.1d">italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="\beta_{2}" class="ltx_Math" display="inline" id="A1.T4.5.5.2.m2.1"><semantics id="A1.T4.5.5.2.m2.1a"><msub id="A1.T4.5.5.2.m2.1.1" xref="A1.T4.5.5.2.m2.1.1.cmml"><mi id="A1.T4.5.5.2.m2.1.1.2" xref="A1.T4.5.5.2.m2.1.1.2.cmml">β</mi><mn id="A1.T4.5.5.2.m2.1.1.3" xref="A1.T4.5.5.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.T4.5.5.2.m2.1b"><apply id="A1.T4.5.5.2.m2.1.1.cmml" xref="A1.T4.5.5.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T4.5.5.2.m2.1.1.1.cmml" xref="A1.T4.5.5.2.m2.1.1">subscript</csymbol><ci id="A1.T4.5.5.2.m2.1.1.2.cmml" xref="A1.T4.5.5.2.m2.1.1.2">𝛽</ci><cn id="A1.T4.5.5.2.m2.1.1.3.cmml" type="integer" xref="A1.T4.5.5.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.5.5.2.m2.1c">\beta_{2}</annotation><annotation encoding="application/x-llamapun" id="A1.T4.5.5.2.m2.1d">italic_β start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.5.3">(0.9, 0.98)</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.17.12">
<td class="ltx_td ltx_align_left" id="A1.T4.5.17.12.1">Clip Norm</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.17.12.2">2.0</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.18.13">
<td class="ltx_td ltx_align_left" id="A1.T4.5.18.13.1">Dropout</td>
<td class="ltx_td ltx_align_right" id="A1.T4.5.18.13.2">0.1</td>
</tr>
<tr class="ltx_tr" id="A1.T4.5.19.14">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T4.5.19.14.1">Weight Decay</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.5.19.14.2">0.01</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T4.8.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="A1.T4.9.2" style="font-size:90%;">Pretraining hyperparameters for our <span class="ltx_ERROR undefined" id="A1.T4.9.2.1">\nolbreaks</span>AST-T5 model.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Evaluation Results on EvalPlus</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS4.p1">
<p class="ltx_p" id="A1.SS4.p1.1">We extend our evaluation to include EvalPlus&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib25" title="">2023</a>)</cite>, a more rigorous benchmark that enhances the original HumanEval and MBPP datasets with a substantial number of additional test cases. EvalPlus is designed to provide a more accurate evaluation of the correctness of programs produced by LLMs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS4.p2">
<p class="ltx_p" id="A1.SS4.p2.1">For our tests on HumanEval+ and MBPP+, we use the same hyperparameters used in our evaluations of HumanEval and MBPP. It is important to note that the hyperparameter configurations used in our study are not directly comparable to those used for the models listed on the EvalPlus leaderboard<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://evalplus.github.io/leaderboard.html" title="">https://evalplus.github.io/leaderboard.html</a></span></span></span>. Our results are compared against established models including GPT-Neo, GPT-J, InCoder, and CodeGen-2&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Nijkamp et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib28" title="">2023a</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A1.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T5.3.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="A1.T5.4.2" style="font-size:90%;">Performance of <span class="ltx_ERROR undefined" id="A1.T5.4.2.1">\nolbreaks</span>AST-T5 on HumanEval+ and MBPP+ benchmarks, compared with reported numbers of language models listed on the EvalPlus leaderboard. The evaluation metric used is Pass@1.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T5.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T5.5.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="A1.T5.5.1.1.1"></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A1.T5.5.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T5.5.1.1.2.1">#Params</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A1.T5.5.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T5.5.1.1.3.1">HumanEval+</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A1.T5.5.1.1.4"><span class="ltx_text ltx_font_bold" id="A1.T5.5.1.1.4.1">MBPP+</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T5.5.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T5.5.2.1.1">GPT-Neo</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.5.2.1.2">2.7B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.5.2.1.3">6.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.5.2.1.4">7.9</td>
</tr>
<tr class="ltx_tr" id="A1.T5.5.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T5.5.3.2.1">GPT-J</th>
<td class="ltx_td ltx_align_right" id="A1.T5.5.3.2.2">6B</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.3.2.3">11.0</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.3.2.4">12.2</td>
</tr>
<tr class="ltx_tr" id="A1.T5.5.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T5.5.4.3.1">InCoder-1.3B</th>
<td class="ltx_td ltx_align_right" id="A1.T5.5.4.3.2">1.3B</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.4.3.3">11.0</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.4.3.4">12.2</td>
</tr>
<tr class="ltx_tr" id="A1.T5.5.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T5.5.5.4.1">InCoder-6.7B</th>
<td class="ltx_td ltx_align_right" id="A1.T5.5.5.4.2">6.7B</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.5.4.3">12.2</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.5.4.4">15.9</td>
</tr>
<tr class="ltx_tr" id="A1.T5.5.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T5.5.6.5.1">CodeGen2-1B</th>
<td class="ltx_td ltx_align_right" id="A1.T5.5.6.5.2">1B</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.6.5.3">9.1</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.6.5.4">11.0</td>
</tr>
<tr class="ltx_tr" id="A1.T5.5.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T5.5.7.6.1">CodeGen2-3B</th>
<td class="ltx_td ltx_align_right" id="A1.T5.5.7.6.2">3B</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.7.6.3">12.8</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.7.6.4">15.9</td>
</tr>
<tr class="ltx_tr" id="A1.T5.5.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T5.5.8.7.1">CodeGen2-7B</th>
<td class="ltx_td ltx_align_right" id="A1.T5.5.8.7.2">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.8.7.3">17.7</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.8.7.4">18.3</td>
</tr>
<tr class="ltx_tr" id="A1.T5.5.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T5.5.9.8.1">CodeGen2-16B</th>
<td class="ltx_td ltx_align_right" id="A1.T5.5.9.8.2">16B</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.9.8.3">16.5</td>
<td class="ltx_td ltx_align_right" id="A1.T5.5.9.8.4">19.5</td>
</tr>
<tr class="ltx_tr" id="A1.T5.5.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A1.T5.5.10.9.1">AST-T5 (Ours)</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T5.5.10.9.2">277M</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T5.5.10.9.3">12.8</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T5.5.10.9.4">19.3</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS4.p3">
<p class="ltx_p" id="A1.SS4.p3.1">As shown in <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.T5" title="In A.4 Evaluation Results on EvalPlus ‣ Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a>, our 277M-parameter <span class="ltx_ERROR undefined" id="A1.SS4.p3.1.1">\nolbreaks</span>AST-T5 outperforms larger models like InCoder-6.7B and CodeGen2-1B, showing the effectiveness and parameter efficiency of <span class="ltx_ERROR undefined" id="A1.SS4.p3.1.2">\nolbreaks</span>AST-T5.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Evaluation Results on Multi-Lingual Code Generation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A1.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T6.3.1.1" style="font-size:90%;">Table 6</span>: </span><span class="ltx_text" id="A1.T6.4.2" style="font-size:90%;">Results of <span class="ltx_ERROR undefined" id="A1.T6.4.2.1">\nolbreaks</span>AST-T5 on multi-lingual HumanEval and MBXP compared with reported results of established language models. The evaluation metric is Pass@1.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T6.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T6.5.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="A1.T6.5.1.1.1"></th>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A1.T6.5.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T6.5.1.1.2.1">#Params</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A1.T6.5.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T6.5.1.1.3.1">HumanEval</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A1.T6.5.1.1.4"><span class="ltx_text ltx_font_bold" id="A1.T6.5.1.1.4.1">MBXP</span></td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="A1.T6.5.2.2.1"></th>
<td class="ltx_td" id="A1.T6.5.2.2.2"></td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.2.2.3">Python</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.2.2.4">Java</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.2.2.5">Python</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.2.2.6">Java</td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T6.5.3.3.1">CodeGen-multi</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T6.5.3.3.2">350M</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T6.5.3.3.3">7.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T6.5.3.3.4">5.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T6.5.3.3.5">7.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T6.5.3.3.6">8.2</td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.5.4.4.1">CodeGen-mono</th>
<td class="ltx_td ltx_align_right" id="A1.T6.5.4.4.2">350M</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.4.4.3">10.3</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.4.4.4">3.1</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.4.4.5"><span class="ltx_text ltx_font_bold" id="A1.T6.5.4.4.5.1">14.6</span></td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.4.4.6">1.9</td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.5.5.5.1">AST-T5 (Ours)</th>
<td class="ltx_td ltx_align_right" id="A1.T6.5.5.5.2">277M</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.5.5.3">14.0</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.5.5.4"><span class="ltx_text ltx_font_bold" id="A1.T6.5.5.5.4.1">10.6</span></td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.5.5.5"><span class="ltx_text ltx_font_bold" id="A1.T6.5.5.5.5.1">23.9</span></td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.5.5.6"><span class="ltx_text ltx_font_bold" id="A1.T6.5.5.5.6.1">9.8</span></td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T6.5.6.6.1">BLOOM</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T6.5.6.6.2">7.1B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T6.5.6.6.3">7.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T6.5.6.6.4">8.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T6.5.6.6.5">7.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T6.5.6.6.6">7.8</td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.5.7.7.1">OPT</th>
<td class="ltx_td ltx_align_right" id="A1.T6.5.7.7.2">13B</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.7.7.3">0.6</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.7.7.4">0.6</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.7.7.5">1.4</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.7.7.6">1.4</td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.5.8.8.1">CodeGen-multi</th>
<td class="ltx_td ltx_align_right" id="A1.T6.5.8.8.2">2B</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.8.8.3">11.0</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.8.8.4">11.2</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.8.8.5">18.8</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.8.8.6">19.5</td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.5.9.9.1">CodeGen-mono</th>
<td class="ltx_td ltx_align_right" id="A1.T6.5.9.9.2">2B</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.9.9.3">20.7</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.9.9.4">5.0</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.9.9.5">31.7</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.9.9.6">16.7</td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.5.10.10.1">CodeGen-multi</th>
<td class="ltx_td ltx_align_right" id="A1.T6.5.10.10.2">6B</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.10.10.3">15.2</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.10.10.4">10.6</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.10.10.5">22.5</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.10.10.6">21.7</td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.5.11.11.1">CodeGen-mono</th>
<td class="ltx_td ltx_align_right" id="A1.T6.5.11.11.2">6B</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.11.11.3">19.5</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.11.11.4">8.7</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.11.11.5">37.2</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.11.11.6">19.8</td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.5.12.12.1">CodeGen-multi</th>
<td class="ltx_td ltx_align_right" id="A1.T6.5.12.12.2">16B</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.12.12.3">17.1</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.12.12.4">16.2</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.12.12.5">24.2</td>
<td class="ltx_td ltx_align_right" id="A1.T6.5.12.12.6">28.0</td>
</tr>
<tr class="ltx_tr" id="A1.T6.5.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A1.T6.5.13.13.1">CodeGen-mono</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T6.5.13.13.2">16B</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T6.5.13.13.3">22.6</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T6.5.13.13.4">22.4</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T6.5.13.13.5">40.6</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T6.5.13.13.6">26.8</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS5.p1">
<p class="ltx_p" id="A1.SS5.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.T6" title="In A.5 Evaluation Results on Multi-Lingual Code Generation ‣ Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">6</span></a> presents a comparative analysis of our <span class="ltx_ERROR undefined" id="A1.SS5.p1.1.1">\nolbreaks</span>AST-T5 model on Python and Java subsets of the multi-lingual HumanEval and MBXP benchmarks <cite class="ltx_cite ltx_citemacro_citep">(Athiwaratkun et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib4" title="">2023</a>)</cite>. This analysis includes models such as BLOOM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(BigScience, <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib7" title="">2021</a>)</cite>, OPT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib45" title="">2022</a>)</cite>, and various configurations of CodeGen <cite class="ltx_cite ltx_citemacro_citep">(Nijkamp et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib29" title="">2023b</a>)</cite>, as reported in <cite class="ltx_cite ltx_citemacro_citet">Athiwaratkun et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib4" title="">2023</a>)</cite>. Our results show <span class="ltx_ERROR undefined" id="A1.SS5.p1.1.2">\nolbreaks</span>AST-T5’s superior performance across all benchmarks compared to the CodeGen-multi-350M.
Furthermore, AST-T5, having 277M parameters, outperforms larger counterparts like BLOOM-7.1B and OPT-13B.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>Evaluation Results in CodeBLEU</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A1.T7">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T7.3.1.1" style="font-size:90%;">Table 7</span>: </span><span class="ltx_text" id="A1.T7.4.2" style="font-size:90%;">Results of <span class="ltx_ERROR undefined" id="A1.T7.4.2.1">\nolbreaks</span>AST-T5 on CONCODE with reported results of established language models. The evaluation metric is exact match score and CodeBLEU.</span></figcaption>
<br class="ltx_break">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T7.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T7.5.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="A1.T7.5.1.1.1"></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A1.T7.5.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T7.5.1.1.2.1">EM</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A1.T7.5.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T7.5.1.1.3.1">CodeBLEU</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T7.5.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T7.5.2.1.1">GPT-2</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T7.5.2.1.2">17.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T7.5.2.1.3">29.7</td>
</tr>
<tr class="ltx_tr" id="A1.T7.5.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.5.3.2.1">CodeGPT-2</th>
<td class="ltx_td ltx_align_right" id="A1.T7.5.3.2.2">18.3</td>
<td class="ltx_td ltx_align_right" id="A1.T7.5.3.2.3">32.7</td>
</tr>
<tr class="ltx_tr" id="A1.T7.5.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.5.4.3.1">CodeGPT-adapted</th>
<td class="ltx_td ltx_align_right" id="A1.T7.5.4.3.2">20.1</td>
<td class="ltx_td ltx_align_right" id="A1.T7.5.4.3.3">36.0</td>
</tr>
<tr class="ltx_tr" id="A1.T7.5.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.5.5.4.1">PLBART</th>
<td class="ltx_td ltx_align_right" id="A1.T7.5.5.4.2">18.8</td>
<td class="ltx_td ltx_align_right" id="A1.T7.5.5.4.3">38.5</td>
</tr>
<tr class="ltx_tr" id="A1.T7.5.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.5.6.5.1">CodeT5-Small</th>
<td class="ltx_td ltx_align_right" id="A1.T7.5.6.5.2">21.6</td>
<td class="ltx_td ltx_align_right" id="A1.T7.5.6.5.3">41.4</td>
</tr>
<tr class="ltx_tr" id="A1.T7.5.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.5.7.6.1">CodeT5-Base</th>
<td class="ltx_td ltx_align_right" id="A1.T7.5.7.6.2">22.3</td>
<td class="ltx_td ltx_align_right" id="A1.T7.5.7.6.3">43.2</td>
</tr>
<tr class="ltx_tr" id="A1.T7.5.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A1.T7.5.8.7.1">AST-T5 (Ours)</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T7.5.8.7.2"><span class="ltx_text ltx_font_bold" id="A1.T7.5.8.7.2.1">22.9</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T7.5.8.7.3"><span class="ltx_text ltx_font_bold" id="A1.T7.5.8.7.3.1">45.0</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS6.p1">
<p class="ltx_p" id="A1.SS6.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#A1.T7" title="In A.6 Evaluation Results in CodeBLEU ‣ Appendix A Appendix ‣ AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">7</span></a> presents the performance of various models on the Concode dataset using the CodeBLEU metric, as reported in <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.03003v4#bib.bib43" title="">2021</a>)</cite>. CodeBLEU, specifically designed for evaluating code synthesis, computes a weighted average of three scores: textual match (BLEU), AST match, and Data Flow Graph (DFG) match. Our findings show a clear correlation between CodeBLEU and exact match scores.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body></html>